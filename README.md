# Deepscent
Deep learning for classifying the time series sensor data generated by cancer detection dogs

[![Run model (open In Colab)](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Withington/deepscent/blob/master/notebooks/deepscent.ipynb) **Run**

[![Train model (open In Colab)](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Withington/deepscent/blob/master/notebooks/deepscent_dev.ipynb) **Train**

[![Build Status](https://travis-ci.com/Withington/deepscent.svg?branch=master)](https://travis-ci.com/Withington/deepscent)
[![Coverage Status](https://coveralls.io/repos/github/Withington/deepscent/badge.svg?branch=master)](https://coveralls.io/github/Withington/deepscent?branch=master)
[![Scrutinizer Code Quality](https://scrutinizer-ci.com/g/Withington/deepscent/badges/quality-score.png?b=master)](https://scrutinizer-ci.com/g/Withington/deepscent/?branch=master)

# Data
Synthetic data is provided to represent the cancer detection dogs' data.

Alternative datasets have been obtained from the [UEA & UCR Time Series 
Classification Repository](http://www.timeseriesclassification.com 
"timeseriesclassification.com").

 Anthony Bagnall, Jason Lines, Aaron Bostrom, James Large and Eamonn 
 Keogh, The Great Time Series Classification Bake Off: a Review and 
 Experimental Evaluation of Recent Algorithmic Advances, Data Mining 
 and Knowledge Discovery, 31(3), 2017". [Paper link.](https://link.springer.com/article/10.1007/s10618-016-0483-9 
 "Bagnall et al. (2017)")
 

# How to run locally
## Prerequisites
TensorFlow - For GPU support, TensorFlow recommends using their Docker 
image to simplify installation and avoid library conflicts (Linux only).

Follow [Tensorflow's instuctions](https://www.tensorflow.org/install/gpu "TensorFlow Docker")
 to install Docker and nvidia-docker.

## Run
```
cd deepscent
```

The image base has tensorflow configured to run on GPUs.

```
docker build -t deepscent_gpu dockerfiles/deepscent_gpu
```

Run the Docker container, mount volumes and launch Jupyter Notebook.
```
docker run --runtime=nvidia -it \
--name deepscent \
-u $(id -u):$(id -g) \
-v "$(pwd)"/notebooks:/tf/notebooks/deepscent/notebooks \
-v "$(pwd)"/data:/tf/notebooks/deepscent/data:ro \
-v "$(pwd)"/logs:/tf/notebooks/deepscent/logs \
-p 8888:8888 deepscent_gpu
```
This returns a URL where you can open the Jupyter Notebook. Navigate 
to notebooks/deepscent/notebooks and open deepscent.ipynb or 
deepscent_dev.ipynb.

### Alternative - run on CPU

```
docker build -t deepscent_cpu dockerfiles/deepscent_cpu
```

```
docker run -it \
--name deepscent \
-u $(id -u):$(id -g) \
-v "$(pwd)"/notebooks:/tf/notebooks/deepscent/notebooks \
-v "$(pwd)"/data:/tf/notebooks/deepscent/data:ro \
-v "$(pwd)"/logs:/tf/notebooks/deepscent/logs \
-p 8888:8888 deepscent_cpu
```

