{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of diagnostic tests\n",
    "\n",
    " Dummy data is used to represent cancer detection dogs' data. It in no way reflects the true data collected.\n",
    " \n",
    " The input to this notebook is a table of the dogs' operant responses to various scent samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "file = 'dog_behaviour_database_dummy.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and remove unneeded rows and columns\n",
    "data_input = pd.read_csv(file)\n",
    "data = data_input[data_input['Is Info Row?']==False]\n",
    "cols = [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "data = data.drop(data.columns[cols],axis=1)\n",
    "data.Run = data.Run.astype(int)\n",
    "data.Pass = data.Pass.astype(int)\n",
    "dogs = data['Dog name'].unique()\n",
    "print('The dogs\\' names are',dogs, '\\n')\n",
    "print('Example data rows:', '\\n')\n",
    "print(data.head())\n",
    "print('\\nDescription of the data:')\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data slice. Show the data for one dog on one particular pass number\n",
    "dog = data['Dog name'] == dogs[0]\n",
    "pass_no = data['Pass'] == 1\n",
    "print(data[dog & pass_no].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create re-shaped data, one row for each sample.\n",
    "# Select position 1 samples\n",
    "df_pos1 = data\n",
    "df_pos1 = df_pos1.drop(['Concentration2', 'Concentration3','DogCorrect2', 'DogCorrect3','Result2', 'Result3'], axis=1)\n",
    "df_pos1.rename(index=str, columns={'Concentration1': 'Concentration', 'DogCorrect1': 'DogCorrect', 'Result1': 'Result'}, inplace=True)\n",
    "df_pos1['Position'] = 1\n",
    "# Select position 2 samples\n",
    "df_pos2 = data\n",
    "df_pos2 = df_pos2.drop(['Concentration1', 'Concentration3','DogCorrect1', 'DogCorrect3','Result1', 'Result3'], axis=1)\n",
    "df_pos2.rename(index=str, columns={'Concentration2': 'Concentration', 'DogCorrect2': 'DogCorrect', 'Result2': 'Result'}, inplace=True)\n",
    "df_pos2['Position'] = 2\n",
    "# Select position 3 samples\n",
    "df_pos3 = data\n",
    "df_pos3 = df_pos3.drop(['Concentration1', 'Concentration2','DogCorrect1', 'DogCorrect2','Result1', 'Result2'], axis=1)\n",
    "df_pos3.rename(index=str, columns={'Concentration3': 'Concentration', 'DogCorrect3': 'DogCorrect', 'Result3': 'Result'}, inplace=True)\n",
    "df_pos3['Position'] = 3\n",
    "# Concatenate the three positions\n",
    "df_samples = pd.concat([df_pos1, df_pos2, df_pos3])\n",
    "# Add true class, y_true, and predicted class, y_pred. Class 0 is negative scent sample, class 1 is a positive scent sample.\n",
    "df_samples['y_true'] = [1 if x > 0 else 0 for x in df_samples['Concentration']]\n",
    "df_samples['y_pred'] = [1 if x == 'TP' or x=='FP' else 0 for x in df_samples['Result']]\n",
    "print(df_samples.head())\n",
    "df_samples.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show each dog's results\n",
    "\n",
    "fig, ax = plt.subplots(1, len(dogs))\n",
    "if df_samples.shape[0] < 100:\n",
    "    upper = 20\n",
    "else:\n",
    "    upper = 1200\n",
    "    \n",
    "order = ['TP', 'TN', 'FP', 'FN']\n",
    "colors = ['lime', 'palegreen', 'lightsalmon', 'red']\n",
    "i = 0\n",
    "for d in dogs:\n",
    "    dog = df_samples['Dog name'] == d\n",
    "    axes = df_samples[dog]['Result'].value_counts().reindex(order).plot(\"bar\", ax=ax[i], color=colors)\n",
    "    axes.set_title(d)\n",
    "    axes.set_ylim(0,upper)\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart to compare dog performance\n",
    "pivot = pd.pivot_table(df_samples,index=['Dog name', 'Result'], values=['Concentration'], aggfunc=[len,max,min])\n",
    "print(pivot)\n",
    "\n",
    "colors = ['red', 'lightsalmon', 'palegreen', 'lime' ]   \n",
    "df_samples.groupby('Dog name')['Result'] \\\n",
    "    .value_counts() \\\n",
    "    .sort_index(ascending=False) \\\n",
    "    .unstack(level=1) \\\n",
    "    .plot.bar(stacked=True, color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "temp = df_samples.groupby('Dog name')[['Dog name','DogCorrect']]\n",
    "print(temp.describe())\n",
    "print(temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results per dog and results as they relate to concentration  \n",
    "print('\\nCorrectness count:')   \n",
    "print(df_samples.groupby(['Dog name', 'DogCorrect'])['DogCorrect'].aggregate(len).unstack())\n",
    "print('\\nResults count:')\n",
    "print(df_samples.groupby(['Dog name', 'Result'])['Result'].aggregate(len).unstack())\n",
    "print('\\nMinimum concentration:')\n",
    "print(df_samples.groupby(['Dog name', 'Result'])['Concentration'].aggregate(min).unstack())\n",
    "print('\\nMaximum concentration:')\n",
    "print(df_samples.groupby(['Dog name', 'Result'])['Concentration'].aggregate(max).unstack())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High level description of the data\n",
    "df_cat = df_samples.astype('category')\n",
    "\n",
    "df_cat.dtypes\n",
    "df_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate and display metrics\n",
    "print('\\nResults count:')   \n",
    "results = df_samples.pivot_table('Run', index='Dog name', columns='Result', aggfunc=len, fill_value=0, margins=True)\n",
    "print(results)\n",
    "\n",
    "\n",
    "accuracy = results.div( results.iloc[:,-1], axis=0 )\n",
    "print('\\nAccuracy:')\n",
    "print(accuracy)\n",
    "\n",
    "# Calculate ratios. FNR, false negative ratio, etc.\n",
    "results['TPR'] = results.TP/(results.FP+results.TP)\n",
    "results['FPR'] = results.FP/(results.FP+results.TP)\n",
    "results['TNR'] = results.TN/(results.FN+results.TN)\n",
    "results['FNR'] = results.FN/(results.FN+results.TN)\n",
    "print('\\nRatios:')\n",
    "print('Sensitivity (aka recall) = TPR')\n",
    "print('Specificity = TNR')\n",
    "print(results[['TPR', 'FPR', 'TNR', 'FNR']])\n",
    "\n",
    "# Calculate likelihood ratios and diagnostic odds ratio\n",
    "results['LR+'] = results.TPR/(results.FPR)\n",
    "results['LR-'] = (1-results.TPR)/(results.TNR)\n",
    "results['DOR'] = results['LR+']/results['LR-']\n",
    "print('\\nLikelihood ratios:')\n",
    "print('Tharwat, A. (2018). Classification assessment methods. Applied Computing and Informatics.')\n",
    "print('LR+ measures how much the odds of the disease increases when the diagnositic test is positive')\n",
    "print('LR- measures how much the odds of the disease decreases when the diagnositic test is negative')\n",
    "print('DOR, diagnostic odds ratio, an estimate of the discriminative ability of the diagnostic test')\n",
    "print('DOR can be used to compare two diagnostic tests')\n",
    "print('DOR = LR+/LR-')\n",
    "print(results[['LR+', 'LR-', 'DOR']])\n",
    "\n",
    "# Calculate Youden's index\n",
    "results['YI'] = results.TPR+results.TNR-1\n",
    "print('\\nYouden\\'s Index, YI:')\n",
    "print('Tharwat, A. (2018). Classification assessment methods. Applied Computing and Informatics.')\n",
    "print('aka Bookmaker Informedness, BM')\n",
    "print('YI range is 0-1, with 1 representing a perfect diagnostic test')\n",
    "print(results[['YI']])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(df_samples.y_true, df_samples.y_pred)\n",
    "print('Confusion matrix:')\n",
    "print(cm)\n",
    "print('\\nNormalised confusion matrix:')\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm)\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Normalised confusion matrix'):\n",
    "    # Plot the normalised confusion matrix\n",
    "    # Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "    # 'Confusion Matrix' https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "    classes = ['Negative', 'Positive']\n",
    "    cmap=plt.cm.Blues\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for one dog\n",
    "dog_name = dogs[0]\n",
    "dog = df_samples['Dog name'] == dog_name\n",
    "print('Data for', dog_name)\n",
    "cm = confusion_matrix(df_samples[dog].y_true, df_samples[dog].y_pred)\n",
    "print('\\nNormalised confusion matrix for', dog_name, ' :')\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm) \n",
    "title = 'Normalised confusion matrix for '+ dog_name\n",
    "plot_confusion_matrix(cm, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for excluding samples below a certain concentration level\n",
    "threshold = 1/1e5\n",
    "txt = '1/100,000'\n",
    "above = df_samples['Concentration'] >= threshold \n",
    "negative = df_samples.y_true == 0\n",
    "cond = above | negative\n",
    "#print(df_samples[cond].head(10))\n",
    "cm = confusion_matrix(df_samples[cond].y_true, df_samples[cond].y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "title = 'Normalised confusion matrix for concentrations above or equal to '+ str(threshold)+' (i.e. '+txt+')'\n",
    "plot_confusion_matrix(cm, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for excluding samples below a certain concentration level\n",
    "threshold = 1/25e6\n",
    "txt = '1/25M'\n",
    "above = df_samples['Concentration'] >= threshold \n",
    "negative = df_samples.y_true == 0\n",
    "cond = above | negative\n",
    "#print(df_samples[cond].head(10))\n",
    "cm = confusion_matrix(df_samples[cond].y_true, df_samples[cond].y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "title = 'Normalised confusion matrix for concentrations above or equal to '+ str(threshold)+' (i.e. '+txt+')'\n",
    "plot_confusion_matrix(cm, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for only the last pass in any run\n",
    "cond = df_samples['IsLastPass'] == True \n",
    "print(df_samples[cond].describe())\n",
    "cm = confusion_matrix(df_samples[cond].y_true, df_samples[cond].y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "title = 'Normalised confusion matrix for only the last pass in any run'\n",
    "plot_confusion_matrix(cm, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
