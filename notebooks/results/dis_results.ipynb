{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, RepeatedStratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color palettes for plots\n",
    "sns.set(style = 'whitegrid')\n",
    "colors = sns.color_palette()\n",
    "\n",
    "clr_model_all  = sns.color_palette('muted')\n",
    "clr_model_all.insert(2, clr_model_all[0])\n",
    "clr_model_all.pop(0)\n",
    "\n",
    "clr_model_tuned  = sns.color_palette('muted')\n",
    "clr_model_tuned.insert(2, clr_model_tuned[0])\n",
    "clr_model_tuned.pop(0)\n",
    "clr_model_tuned.append(clr_model_tuned[0])\n",
    "clr_model_tuned.pop(0)\n",
    "\n",
    "clrdogs = sns.color_palette(['red', 'green', 'yellow', 'blue'])\n",
    "\n",
    "if False:\n",
    "    print('clr_model_all')\n",
    "    sns.palplot(clr_model_all)\n",
    "    print('clr_model_tuned')\n",
    "    sns.palplot(clr_model_tuned)\n",
    "    \n",
    "sns.set_palette(clr_model_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(ax, plt):\n",
    "    ax.set_ylabel('Validation accuracy')\n",
    "    plt.ylim(bottom=0.35, top=1.05)\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "    ax.set_xlabel('Dataset')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def print_stats(data, name):\n",
    "    print(name,  ':')\n",
    "    print('Quantiles:\\n', data['val_acc'].quantile([0.25, 0.5, 0.75]) )\n",
    "    print('Mean:', data['val_acc'].mean())\n",
    "    \n",
    "def print_means(data, names):\n",
    "    print('Mean averages:')\n",
    "    for d, n, in zip(data, names):\n",
    "        print(d['val_acc'].mean(), n)\n",
    "        \n",
    "\n",
    "def print_wilcoxon(all_data):\n",
    "    ''' Print the pair-wise Wilcoxon signed-rank pvalues for all pairs of columns in all_data '''\n",
    "    # Wilcoxon t-test\n",
    "    print('Wilcoxon signed rank test pvalues')\n",
    "    for i in range(len(all_data)):\n",
    "        for j in range(i+1, len(all_data)):\n",
    "            statistic, pvalue = stats.wilcoxon(all_data[i], all_data[j])\n",
    "            #print(i, j, pvalue)\n",
    "            if pvalue > 0.05:\n",
    "                print('These two result sets could be drawn from the same distribution:', i, ',', j)\n",
    "            \n",
    "            \n",
    "def plot_confusion_matrix(cm, title='Normalised confusion matrix', name=''):\n",
    "    ''' Plot the normalised confusion matrix\n",
    "    Parameters\n",
    "    cm : array - normalised confusion matrix\n",
    "    Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "    'Confusion Matrix' https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "    '''\n",
    "    classes = ['Positive', 'Negative']\n",
    "    cmap=plt.cm.Blues\n",
    "    sns.set_style('dark')\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(format=FuncFormatter('{0:.0%}'.format))\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.clim(0, 1)\n",
    "    fmt = '.0%'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.tight_layout()\n",
    "    file_name = 'cm_devnet_'+name+'.png'\n",
    "    plt.savefig(file_name, bbox_inches='tight')\n",
    "    sns.set(style = 'whitegrid')\n",
    "    \n",
    "    \n",
    "def append_result_set(file, name, all_data, all_end_test_data, all_names, results):\n",
    "    ''' Get results data from file. Against the input name, append the mean and std of this result set to \n",
    "    all_data, all_end_test_data, all_names, results '''\n",
    "    data = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time', 'end_test_acc'])\n",
    "    assert(data.shape[1]==6)\n",
    "    all_data.append(data['val_acc'])\n",
    "    all_end_test_data.append(data['end_test_acc'])\n",
    "    all_names.append(name)\n",
    "    results.append([all_names[-1], data['val_acc'].mean(), data['val_acc'].std(), \n",
    "                data['end_test_acc'].mean(), data['end_test_acc'].std()])\n",
    "    \n",
    "    \n",
    "def plot_acc(accuracy_results, result_names, title, \n",
    "             ylabel='Validation accuracy', ylim=[0.3, 1.05]):\n",
    "    ''' Show a box plot of accuracy data and save image to file'''\n",
    "    ax = sns.boxplot(data=accuracy_results)\n",
    "    ax = sns.swarmplot(data=accuracy_results, color='black')\n",
    "    title = title\n",
    "    plt.suptitle(title)\n",
    "    xticks = list(range(len(result_names)))\n",
    "    plt.xticks(xticks, result_names)\n",
    "    format_plot(ax, plt)\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    plt.ylim(bottom=ylim[0], top=ylim[1])\n",
    "    return ax, plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    data = np.loadtxt(Path(filename))\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def dataset_size(filename):\n",
    "    if 'private_dog0' == filename or 'private_dog1' == filename or 'private_dog2' == filename:\n",
    "        fdir = '../../data/private_data/private_events_dev' \n",
    "    elif 'private' in filename:\n",
    "        fdir = '../../data/private_data/private_events_dev2' \n",
    "        \n",
    "    _, y_train = readucr(fdir+'/'+filename+'/'+filename+'_TRAIN.txt')\n",
    "    _, y_test = readucr(fdir+'/'+filename+'/'+filename+'_TEST.txt')\n",
    "    return y_train.shape[0]+y_test.shape[0]\n",
    "\n",
    "\n",
    "def end_test_dataset_size(filename):\n",
    "    fdir = '../../data/private_data/private_events_dev2' \n",
    "    _, y_endtest = readucr(fdir+'/'+filename+'/'+filename+'_END_TEST.txt')\n",
    "    return y_endtest.shape[0]\n",
    "\n",
    "\n",
    "def sample_sizes(num_dataset, k, m, brackets=True):\n",
    "    ''' Given a dataset size, calculate the number of samples used in the calculations of m iterations\n",
    "    of k-fold cross validation.\n",
    "    Returns \n",
    "    ND \n",
    "        number of data samples used to calculate the validation accuracy \n",
    "    NT\n",
    "        number of tests used run\n",
    "    num_text \n",
    "        a string that can be used in plots to write ND and NT with subscripts\n",
    "    '''\n",
    "    N = num_dataset\n",
    "    ND = str(round(N/k))\n",
    "    NT = str(k*m)\n",
    "    if brackets:\n",
    "        num_text = '($N_D$='+ND+', $N_T$='+NT+')'\n",
    "    else:\n",
    "        num_text = '$N_D$='+ND+', $N_T$='+NT\n",
    "    return ND, NT, num_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example confusion matrix and box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "y_pred = [1, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "title = 'Confusion matrix' # ($N_D$=10)'\n",
    "plot_confusion_matrix(cm_norm, title=title, name='example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame([14, 14, 13, 13, 12, 12, 10, 10, 10, 9])\n",
    "all_data = all_data/15\n",
    "print(all_data)\n",
    "print('mean', all_data[0].mean(), 'std', all_data[0].std())\n",
    "print('quantiles', all_data[0].quantile([0.25, 0.5, 0.75]))\n",
    "\n",
    "ax = sns.boxplot(data=all_data, width=0.2)\n",
    "ax = sns.swarmplot(data=all_data, color='black')\n",
    "title = '10-fold cross validation result ($N_T$=10)'\n",
    "plt.suptitle(title)\n",
    "ax.set_ylabel('Validation accuracy')\n",
    "plt.ylim(bottom=0.35, top=1.05)\n",
    "ax.yaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "ax.set_xlabel('Dataset')\n",
    "plt.xticks([0], ['Example ($N_D$=15)'])\n",
    "plt.savefig('boxplot_example.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm performance of untuned DNNs : GunPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Single train and test. Same train:test split as UCR TSC archive. Reporting validation accuracy and error.', '\\n')\n",
    "\n",
    "print('1-NN (1-nearest neighbor)')\n",
    "print('0.9133333333333333')\n",
    "print(1-0.9133333333333333, 'error\\n')\n",
    "\n",
    "file = '../../logs/2019-05-10T20:18/GunPoint/mlpwang_summary.csv'\n",
    "data1 = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "print(file, '(MLP Wang)')\n",
    "print('No. results:', data1.shape[0])\n",
    "print(data1.iloc[0]['val_acc'].mean())\n",
    "print(1-data1['val_acc'].mean(), 'error\\n')\n",
    "\n",
    "file = '../../logs/2019-03-31T18:07/GunPoint/devnet_summary.csv'\n",
    "data2 = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "print(file, '(FCN Wang)')\n",
    "print('No. results:', data2.shape[0])\n",
    "print(data2['val_acc'].mean())\n",
    "print(1-data2['val_acc'].mean(), 'error\\n')\n",
    "\n",
    "file = '../../logs/2019-03-29T15:29/GunPoint/devnet_summary.csv'\n",
    "#file = '../../logs/2019-05-11T13:42/GunPoint/resnet_summary.csv'\n",
    "data2 = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "print(file, '(ResNet Wang)')\n",
    "print('No. results:', data2.shape[0])\n",
    "print(data2['val_acc'].mean())\n",
    "print(1-data2['val_acc'].mean(), 'error\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross validation\n",
    "ND, NT, num_text = sample_sizes(200, k=10, m=1)\n",
    "print(num_text, '\\n')\n",
    "\n",
    "print('1-NN (1-nearest neighbor)')\n",
    "print(0.9450000000000001)\n",
    "print(0.043779751788545644, '\\n')\n",
    "\n",
    "file = '../../logs/2019-03-17T16:35/GunPoint/mlpwang_summary.csv'\n",
    "data1 = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "name1 = 'GunPoint'\n",
    "print(file, '(MLP Wang)')\n",
    "print(data1['val_acc'].mean())\n",
    "print(data1['val_acc'].std())\n",
    "print('Number of folds', data1['val_acc'].count(), '\\n')\n",
    "\n",
    "file = '../../logs/2019-05-09T09:25/GunPoint/devnet_summary.csv'\n",
    "data2 = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "print(file, '(FCN Wang)')\n",
    "print(data2['val_acc'].mean())\n",
    "print(data2['val_acc'].std())\n",
    "print('Number of folds', data2['val_acc'].count(), '\\n')\n",
    "\n",
    "file = '../../logs/2019-03-18T17:32/GunPoint/resnet_summary.csv'\n",
    "data2 = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "print(file, '(ResNet Wang)')\n",
    "print(data2['val_acc'].mean())\n",
    "print(data2['val_acc'].std())\n",
    "print('Number of folds', data2['val_acc'].count(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Untuned models : all dogs data (balanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list()\n",
    "all_names = list()\n",
    "results = []\n",
    "N = dataset_size('private_balanced')\n",
    "ND, NT, num_text = sample_sizes(N, k=10, m=1)\n",
    "\n",
    "# TODO new files with 4x 3-fold\n",
    "one_nn = '../logs/2019-07-14T13:48/private_balanced/nearestneighbours_summary.csv'\n",
    "mlp = '../../logs/2019-07-14T08:14/private_balanced/devnet_summary.csv'\n",
    "fcn = '../logs/2019-07-14T10:57/private_balanced/devnet_summary.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file = '../../logs/2019-05-10T16:36/private_balanced/nearestneighbours_summary.csv'\n",
    "data = pd.read_csv(file, header=None, names=['val_acc'])\n",
    "all_data.append(data['val_acc'])\n",
    "all_names.append('1-NN')\n",
    "results.append([all_names[-1], all_data[-1].mean(), all_data[-1].std()])\n",
    "\n",
    "file = '../../logs/2019-03-21T14:23/private_balanced/mlpwang_summary.csv'\n",
    "data = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "all_data.append(data['val_acc'])\n",
    "all_names.append('MLP')\n",
    "results.append([all_names[-1], all_data[-1].mean(), all_data[-1].std()])\n",
    "\n",
    "file = '../../logs/2019-05-09T12:30/private_balanced/devnet_summary.csv'\n",
    "data = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "all_data.append(data['val_acc'])\n",
    "all_names.append('FCN')\n",
    "results.append([all_names[-1], all_data[-1].mean(), all_data[-1].std()])\n",
    "\n",
    "file = '../../logs/2019-03-20T19:47/private_balanced/resnet_summary.csv'\n",
    "data = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "all_data.append(data['val_acc'])\n",
    "all_names.append('ResNet')\n",
    "results.append([all_names[-1], all_data[-1].mean(), all_data[-1].std()])\n",
    "\n",
    "print(results)\n",
    "print_wilcoxon(all_data)\n",
    "sns.set_palette(clr_model_all)\n",
    "plot_acc(all_data, all_names, 'All dogs dataset '+num_text, ylim=[0.45, 0.9])\n",
    "plt.savefig('pubmodels_alldogs.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Untuned models : all dogs correct data (balanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list()\n",
    "all_end_test_data = list()\n",
    "all_names = list()\n",
    "results = []\n",
    "end_test_results = []\n",
    "k=3\n",
    "m=4\n",
    "N = dataset_size('private_correct_plus')\n",
    "ND, NT, num_text = sample_sizes(N, k, m, brackets=False) \n",
    "\n",
    "\n",
    "# Get results sets\n",
    "file = '../../logs/2019-07-14T16:26/private_correct_plus/nearestneighbours_summary.csv' # 1-NN, instant\n",
    "data = pd.read_csv(file, header=None, names=['val_acc', 'end_test_acc'])\n",
    "all_data.append(data['val_acc'])\n",
    "all_end_test_data.append(data['end_test_acc'])\n",
    "all_names.append('1-NN')\n",
    "results.append([all_names[-1], data['val_acc'].mean(), data['val_acc'].std(), \n",
    "            data['end_test_acc'].mean(), data['end_test_acc'].std()])\n",
    "\n",
    "\n",
    "file = '../../logs/2019-07-07T17:40/private_correct_plus/devnet_summary.csv' # MLP Wang 1h10m\n",
    "ND, __, __ = sample_sizes(dataset_size('private_dog1_correct_plus'), k, m)\n",
    "append_result_set(file, 'MLP', all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "file = '../../logs/2019-07-08T16:49/private_correct_plus/devnet_summary.csv' # FCN 1h15m\n",
    "ND, __, __ = sample_sizes(dataset_size('private_dog2_correct_plus'), k, m)\n",
    "append_result_set(file, 'FCN', all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "file = '../../logs/2019-07-07T20:52/private_correct_plus/devnet_summary.csv' # ResNet Wang, 12h30m\n",
    "ND, __, __ = sample_sizes(dataset_size('private_correct_plus'), k, m)\n",
    "append_result_set(file, 'ResNet', all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "\n",
    "# Plot\n",
    "save_filename = 'pubmodels_alldogs_correct'\n",
    "sns.set_palette(clr_model_all)\n",
    "plot_acc(all_data, all_names, '\\tDog correct dataset (all dogs, '+num_text+')', \n",
    "         ylim=[0.45, 0.9])\n",
    "plt.savefig(save_filename+'.png', bbox_inches='tight')\n",
    "\n",
    "print_wilcoxon(all_data)\n",
    "\n",
    "# Print and save results\n",
    "res = pd.DataFrame(results, columns=['set', 'val_acc', 'val_std', 'end_acc', 'end_std'])\n",
    "res = res.replace(to_replace=r'\\n', value=' ', regex=True)\n",
    "res.to_csv(save_filename+'.csv')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on realistic data\n",
    "Lower sample standard deviation on this test set than on all_dogs correct dataset most likely because the test set itself is constant. Whereas, the validation set under k-fold cross validation changes with each iteration of model trainig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end_test_results)\n",
    "title = '\\tRealistic dataset (all dogs, $N_D$='+str(end_test_dataset_size('private_correct_plus'))\n",
    "title = title + ', $N_T$='+NT+')'\n",
    "sns.set_palette(clr_model_all)\n",
    "ax, plt = plot_acc(all_end_test_data, all_names, title, 'Accuracy', ylim=[0.45,0.9])\n",
    "ax.set_xlabel('Model (trained on dog correct data)')\n",
    "plt.savefig(save_filename+'_realistic.png', bbox_inches='tight')\n",
    "print_wilcoxon(all_end_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Untuned MLP : dogs correct  : personal vs impersonal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list()\n",
    "all_end_test_data = list()\n",
    "all_names = list()\n",
    "results = []\n",
    "end_test_results = []\n",
    "k = 3\n",
    "m = 4\n",
    "N = dataset_size('private_correct_plus')\n",
    "ND, NT, num_text = sample_sizes(N, k, m, brackets=False) \n",
    "\n",
    "\n",
    "all_data = list()\n",
    "all_end_test_data = list()\n",
    "all_names = list()\n",
    "results = []\n",
    "end_test_results = []\n",
    "N = dataset_size('private_correct_plus')\n",
    "ND, NT, num_text = sample_sizes(N, k=3, m=4) \n",
    "\n",
    "# Get results sets\n",
    "file = '../../logs/2019-07-12T14:41/private_dog0_correct_plus/devnet_summary.csv'\n",
    "ND, __, __ = sample_sizes(dataset_size('private_dog0_correct_plus'), k, m)\n",
    "append_result_set(file, 'dog0\\n$N_D$='+str(ND), all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "file = '../../logs/2019-07-12T17:23/private_dog1_correct_plus/devnet_summary.csv'\n",
    "ND, __, __ = sample_sizes(dataset_size('private_dog1_correct_plus'), k, m)\n",
    "append_result_set(file, 'dog1\\n$N_D$='+str(ND), all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "file = '../../logs/2019-07-12T18:34/private_dog2_correct_plus/devnet_summary.csv' \n",
    "ND, __, __ = sample_sizes(dataset_size('private_dog2_correct_plus'), k, m)\n",
    "append_result_set(file, 'dog2\\n$N_D$='+str(ND), all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "file = file = '../../logs/2019-07-07T17:40/private_correct_plus/devnet_summary.csv' \n",
    "ND, __, __ = sample_sizes(dataset_size('private_correct_plus'), k, m)\n",
    "append_result_set(file, 'all dogs\\n$N_D$='+str(ND), all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "# Plot\n",
    "save_filename = 'MLP_personal'\n",
    "title = '\\tMLP ($N_T$='+NT+')'\n",
    "with sns.color_palette('Blues',4):\n",
    "    ax, plt = plot_acc(all_data, all_names, title, ylim=[0.45, 1.05])\n",
    "ax.set_xlabel('Dog correct dataset')\n",
    "plt.savefig(save_filename+'.png', bbox_inches='tight')\n",
    "\n",
    "print_wilcoxon(all_data)\n",
    "\n",
    "# Print and save results\n",
    "res = pd.DataFrame(results, columns=['set', 'val_acc', 'val_std', 'end_acc', 'end_std'])\n",
    "res = res.replace(to_replace=r'\\n', value=' ', regex=True)\n",
    "res.to_csv(save_filename+'.csv')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = list()\n",
    "\n",
    "ND = end_test_dataset_size('private_dog0_correct_plus')\n",
    "all_names.append('dog0\\n$N_D$='+str(ND))\n",
    "ND = end_test_dataset_size('private_dog1_correct_plus')\n",
    "all_names.append('dog1\\n$N_D$='+str(ND))\n",
    "ND = end_test_dataset_size('private_dog2_correct_plus')\n",
    "all_names.append('dog2\\n$N_D$='+str(ND))\n",
    "ND = end_test_dataset_size('private_correct_plus')\n",
    "all_names.append('all dogs\\n$N_D$='+str(ND))\n",
    "\n",
    "\n",
    "title = '\\tMLP (trained on dog correct data) ($N_T$='+NT+')'\n",
    "with sns.color_palette('Blues', 4):\n",
    "    ax, plt = plot_acc(all_end_test_data, all_names, title, 'Accuracy', ylim=[0.45, 1.05])\n",
    "ax.set_xlabel('Realistic dataset')\n",
    "plt.savefig(save_filename+'_realistic.png', bbox_inches='tight')\n",
    "print_wilcoxon(all_end_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../../data/private_data/private_events_dev2' \n",
    "fname = 'private_balanced'\n",
    "meta_train = pd.read_csv(datadir+'/'+fname+'/'+fname+'_TRAIN_meta.txt', sep=',', parse_dates=['date'])\n",
    "meta_test = pd.read_csv(datadir+'/'+fname+'/'+fname+'_TEST_meta.txt', sep=',', parse_dates=['date'])\n",
    "meta = pd.concat([meta_train, meta_test])\n",
    "\n",
    "colors = ['red', 'lightsalmon', 'palegreen', 'lime' ]   \n",
    "meta.groupby('dog')['dog_result'] \\\n",
    "    .value_counts() \\\n",
    "    .sort_index(ascending=False) \\\n",
    "    .unstack(level=1) \\\n",
    "    .plot.bar(stacked=True, color=colors)\n",
    "\n",
    "plt.xticks([0, 1, 2], ['0', '1', '2'])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('Number of samples')\n",
    "plt.suptitle('Bio-detection dogs\\' results')\n",
    "plt.legend(title='result')\n",
    "plt.savefig('bar_dogAccuracy.png', bbox_inches='tight')\n",
    "\n",
    "results = meta.pivot_table('run', index='dog', columns='dog_result', aggfunc=len, fill_value=0, margins=True)\n",
    "print(results)\n",
    "\n",
    "\n",
    "# Calculate Accuracy and FNR, false negative rate, etc.\n",
    "P = results.TP+results.FN\n",
    "N = results.TN+results.FP\n",
    "results['Accuracy'] = (results.TP+results.TN)/(P+N)\n",
    "results['TPR'] = results.TP/P\n",
    "results['FPR'] = results.FP/N\n",
    "results['TNR'] = results.TN/N\n",
    "results['FNR'] = results.FN/P\n",
    "print(results[['Accuracy', 'TPR', 'TNR', 'FPR', 'FNR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ND, NT, num_text = sample_sizes(dataset_size('private_dog0_correct_plus'), k=3, m=4)\n",
    "\n",
    "acc = [[ 0.85,0.85, 0.85, 0.82, 0.79, 0.63, 0.53],\n",
    "        [0.84,0.85, 0.84, 0.82, 0.86, 0.73, 0.56],\n",
    "        [0.85,0.84, 0.85, 0.84, 0.85, 0.72, 0.62],\n",
    "        [0.85,0.84, 0.84, 0.84, 0.8, 0.62, 0.52],\n",
    "        [0.84,0.84, 0.84, 0.84, 0.84, 0.59, 0.5],\n",
    "        [0.83,0.84, 0.84, 0.83, 0.84, 0.73, 0.5]]\n",
    "\n",
    "std = [[ 0.045,0.05, 0.047, 0.051, 0.14, 0.16, 0.1],\n",
    "        [0.044,0.042, 0.044, 0.041, 0.053, 0.14, 0.14],\n",
    "        [0.039,0.051, 0.059, 0.049, 0.052, 0.17, 0.17],\n",
    "        [0.053,0.044, 0.049, 0.042, 0.1, 0.18,  np.nan],\n",
    "        [0.047,0.046, 0.046, 0.055, 0.039, 0.16,  np.nan],\n",
    "        [0.042,0.046, 0.051, 0.05, 0.054, 0.17,  np.nan]]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax0 = fig.add_subplot(121)\n",
    "ax1 = fig.add_subplot(122, sharey=ax0)\n",
    "sns.heatmap(acc, cmap='RdYlGn', annot=True, fmt = '.0%', cbar=False, ax=ax0)\n",
    "sns.heatmap(std, cmap='RdYlGn_r', annot=True, fmt = '.1%', cbar=False, ax=ax1)\n",
    "ax0.set_xlabel('Number of hidden layers')\n",
    "ax1.set_xlabel('Number of hidden layers')\n",
    "ax0.set_ylabel('Nodes per layer')\n",
    "ax0.set_xticklabels([2, 3, 4, 5, 6, 7, 8])\n",
    "ax1.set_xticklabels([2, 3, 4, 5, 6, 7, 8])\n",
    "ax0.set_yticklabels([8, 16, 32, 64, 128, 256])\n",
    "ax0.set_title('Mean')\n",
    "ax1.set_title('Sample standard deviation')\n",
    "title = 'Validation accuracy : dog0_correct '+num_text\n",
    "plt.suptitle(title, y=1)     \n",
    "plt.savefig('heatmap_MLP_dog0Correct.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned models : trained on all dogs correct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list()\n",
    "all_end_test_data = list()\n",
    "all_names = list()\n",
    "results = []\n",
    "end_test_results = []\n",
    "N = dataset_size('private_correct_plus')\n",
    "ND, NT, num_text = sample_sizes(N, k=3, m=4) \n",
    "\n",
    "# Get results sets\n",
    "file = '../../logs/2019-05-11T19:09/private_correct_plus/devnet_summary.csv' \n",
    "append_result_set(file, 'MLP\\ntuned', all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "file = '../../logs/2019-07-12T08:47/private_correct_plus/devnet_summary.csv' # FCN TODO - tune it more\n",
    "append_result_set(file, 'FCN\\ntuned', all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "file = '../../logs/2019-07-12T06:35/private_correct_plus/devnet_summary.csv' # ResNet \n",
    "append_result_set(file, 'ResNet\\ntuned', all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "file = '../../logs/2019-07-12T05:31/private_correct_plus/devnet_summary.csv' # CNN\n",
    "append_result_set(file, 'CNN\\ntuned', all_data, all_end_test_data, all_names, results)\n",
    "\n",
    "# Plot\n",
    "save_filename = 'tuned_alldogs_correct'\n",
    "sns.set_palette(clr_model_tuned)\n",
    "ax, plt = plot_acc(all_data, all_names, '\\tDog correct dataset (all dogs) '+num_text, ylim=[0.6, 1.05])\n",
    "plt.savefig(save_filename+'.png', bbox_inches='tight')\n",
    "\n",
    "print_wilcoxon(all_data)\n",
    "\n",
    "# Print and save results\n",
    "res = pd.DataFrame(results, columns=['set', 'val_acc', 'val_std', 'end_acc', 'end_std'])\n",
    "res = res.replace(to_replace=r'\\n', value=' ', regex=True)\n",
    "res.to_csv(save_filename+'.csv')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = '\\tRealistic dataset (all dogs, $N_D$='+str(end_test_dataset_size('private_correct_plus'))\n",
    "title = title + ', $N_T$='+NT+')'\n",
    "sns.set_palette(clr_model_tuned)\n",
    "plot_acc(all_end_test_data, all_names, title, 'Accuracy', ylim=[0.6, 1.05])\n",
    "plt.savefig(save_filename+'_realistic.png', bbox_inches='tight')\n",
    "print_wilcoxon(all_end_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' As per end test on MLP 1000/16/16/16/1\n",
    "../logs/2019-05-12T16:36/private_correct_plus/devnet_summary.csv\n",
    "[[39 38]\n",
    " [ 7 70]]\n",
    "Class balance in test set: 77 to 77 i.e. 0.5\n",
    "'''\n",
    "cm = np.array(  [[0.50649351, 0.49350649],\n",
    "                 [0.09090909, 0.90909091]])\n",
    "acc = (cm[0][0]+cm[1][1])/(cm.sum())\n",
    "plot_confusion_matrix(cm, title='MLP tuned', name='cm_MLPtuned_endTest')\n",
    "\n",
    "\n",
    "dog_cm = np.array([[48, 29],\n",
    "                    [8, 69]])\n",
    "dog_acc = (dog_cm[0][0]+dog_cm[1][1])/(dog_cm.sum())\n",
    "ND = dog_cm.sum()\n",
    "dog_cm = dog_cm.astype('float') / dog_cm.sum(axis=1)[:, np.newaxis]\n",
    "plot_confusion_matrix(dog_cm, title='Bio-detection dogs', name='cm_dog_endTest')\n",
    "\n",
    "print('acc', acc, 'dog_acc', dog_acc, 'ND', ND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' With probability threshold 0.3\n",
    "[[47 30]\n",
    " [15 62]]\n",
    "Calculated accuracy: 0.7077922077922078\n",
    "'''  \n",
    "cm = np.array([[0.61038961, 0.38961039],\n",
    "               [0.19480519, 0.80519481]])\n",
    "plot_confusion_matrix(cm, title='MLP tuned', name='cm_MLPtuned_endTest_threshold_0.3')\n",
    "print('acc', (cm[0][0]+cm[1][1])/(cm.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset size vs accuracy\n",
    "MLP 16/16/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([25,30,40,50,60,70,75,80,90,100,102,125,150,175,200,225,250,275,284])\n",
    "mean_acc = [0.72,0.69,0.7,0.8,0.79,0.82,0.81,0.77,0.79,0.83,0.82,0.81,0.81,0.81,0.83,0.82,0.84,0.83,0.83]\n",
    "acc_std = [0.13,0.12,0.1,0.12,0.082,0.059,0.08,0.062,0.07,0.042,0.046,0.04,0.036,0.055,0.044,0.03,0.055,0.035,0.024]\n",
    "\n",
    "\n",
    "k = 3\n",
    "x_train = np.round((x/k*(k-1)))\n",
    "x_test = x-x_train\n",
    "\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "\n",
    "yerr = [acc_std, acc_std]\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.errorbar(x, mean_acc, yerr,fmt='-o', capsize=4)\n",
    "\n",
    "ax.set_ylim(bottom=0.35, top=1.05)\n",
    "ax.set_xlim(left=0, right=300)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0, 0))\n",
    "plt.suptitle('Effect of dataset size')\n",
    "ax.set_xlabel('Dataset size')\n",
    "ax.set_ylabel('Mean validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_test_acc = [0.64,0.64,0.66,0.68,0.69,0.71,0.69,0.69,0.68,0.7,0.7,0.69,0.68,0.69,0.69,0.69,0.7,0.7,0.7]\n",
    "end_test_std = [0.035,0.042,0.047,0.048,0.025,0.022,0.015,0.035,0.029,0.027,0.015,0.02,0.018,0.016,0.014,0.011,0.011,0.008,0.012]\n",
    "\n",
    "yerr = [end_test_std, end_test_std]\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.errorbar(x_train, end_test_acc, yerr,fmt='-o', capsize=4)\n",
    "\n",
    "ax.set_ylim(bottom=0.5, top=0.8)\n",
    "ax.set_xlim(left=0, right=200)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0, 0))\n",
    "num_text = '($N_D$='+str(154)+', $N_T$='+str(12)+')'\n",
    "plt.suptitle('Realistic dataset test\\n'+num_text)\n",
    "ax.set_xlabel('Size of the training dataset')\n",
    "ax.set_ylabel('Accuracy\\nmean +/- one sample standard deviation')\n",
    "\n",
    "print('Train on', x_train[-1], 'acc', end_test_acc[-1], 'std', end_test_std[-1])\n",
    "print('Train on', x_train[10], 'acc', end_test_acc[10], 'std', end_test_std[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
