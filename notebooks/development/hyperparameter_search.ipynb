{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter grid search\n",
    "NB the input data to the DNN is not normalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.tz import gettz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(757566)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'private_dog0_correct_plus' # private_dog0_correct_plus\n",
    "log_to_file = True\n",
    "\n",
    "tensorboard_dir = '../logs/tensorboard'\n",
    "logs_dir = '../logs'\n",
    "timestamp = '{:%Y-%m-%dT%H:%M}'.format(datetime.now(gettz(\"Europe/London\")))\n",
    "logs_dir = logs_dir +'/' + timestamp\n",
    "tensorboard_dir = tensorboard_dir +'/' + timestamp\n",
    "if 'private' in fname:\n",
    "    fdir = '../data/private_data/private_events_dev2' \n",
    "else:\n",
    "    fdir = '../data' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    ''' Load a dataset from a file in UCR format\n",
    "    space delimited, class labels in the first column.\n",
    "    Returns\n",
    "    X : DNN input data\n",
    "    Y : class labels\n",
    "    '''\n",
    "    data = np.loadtxt(Path(filename))\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def prepare_data(y):\n",
    "    ''' Return y as a categorical array'''\n",
    "    nb_classes = 2\n",
    "    y = (y - y.min())/(y.max()-y.min())*(nb_classes-1)\n",
    "    Y = utils.to_categorical(y, nb_classes)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid search adapted from Machine Learning Mastery\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "\n",
    "# Function to create model, will be parse to KerasClassifier\n",
    "def create_fcn(input_shape=(150,1), num_features0=100, num_features1=100, filter_size=10, pooling_size=3, dropout=0.5):\n",
    "    ''' Create FCN model '''\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(x)\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.MaxPooling1D(pooling_size)(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    full = keras.layers.GlobalAveragePooling1D()(conv_x)\n",
    "    y = Dropout(dropout,name='Dropout')(full)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(full)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "x_train, y_train = readucr(fdir+'/'+fname+'/'+fname+'_TRAIN.txt')\n",
    "x_test, y_test = readucr(fdir+'/'+fname+'/'+fname+'_TEST.txt')\n",
    "X = np.concatenate((x_train, x_test), axis=0)\n",
    "Y = np.concatenate((y_train, y_test), axis=0)\n",
    "X = X.reshape(X.shape + (1,))\n",
    "input_shape = X.shape[1:]\n",
    "print(input_shape)\n",
    "Y = prepare_data(Y)\n",
    "\n",
    "# Add callbacks\n",
    "if False:\n",
    "    callbacks = []\n",
    "    tb_dir = tensorboard_dir+'/'+fname\n",
    "    Path(tb_dir).mkdir(parents=True, exist_ok=True) \n",
    "    callbacks.append(keras.callbacks.TensorBoard(log_dir=tb_dir, histogram_freq=0))\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = 32\n",
    "epochs = 1000\n",
    "num_features0 = 64\n",
    "num_features1 = [64, 128, 256]\n",
    "filter_size = 4\n",
    "pooling_size = 4\n",
    "dropout = [0.2,  0.5]\n",
    "param_grid = dict(num_features1=num_features1, dropout=dropout)\n",
    "\n",
    "# Create model and run the grid search\n",
    "model = KerasClassifier(build_fn=create_fcn, \n",
    "                        input_shape=input_shape,\n",
    "                        num_features0=num_features0, filter_size=filter_size, pooling_size=pooling_size,\n",
    "                        batch_size=batch_size, epochs=epochs,\n",
    "                        verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, error_score=0) #fit_params={'callbacks': callbacks})\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# Summarise results\n",
    "print('Best score:', grid_result.best_score_, 'using: ', grid_result.best_params_)\n",
    "cv = pd.DataFrame(grid_result.cv_results_)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "cv[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Completed at', '{:%Y-%m-%dT%H:%M}'.format(datetime.now(gettz(\"Europe/London\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(logs_dir+'/'+fname).mkdir(parents=True, exist_ok=True)\n",
    "cv.to_csv(Path(logs_dir+'/'+fname+'/grid_search_summary.csv'))\n",
    "print('Results saved to', Path(logs_dir+'/'+fname+'/grid_search_summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
