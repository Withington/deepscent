{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbour Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.tz import gettz\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(455)\n",
    "k_fold_seed = 765432"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = ['private_balanced'] #, 'private_dog0_correct_plus', 'private_dog2_correct'] # List of dataset directory names. WormsTwoClass Lightning2 Earthquakes GunPoint \n",
    "\n",
    "n_neighbors=1\n",
    "\n",
    "k = 3 # For k-fold cross validation. If k=1, the original test-train split is used.\n",
    "m = 4 # Number of repetitions of k-fold cross validation (if k>1).\n",
    "\n",
    "# Input directory\n",
    "if 'private_dog0' == flist[0]:\n",
    "    fdir = '../data/private_data/private_events_dev' \n",
    "elif 'private' in flist[0]:\n",
    "    fdir = '../data/private_data/private_events_dev2' \n",
    "else:\n",
    "    fdir = '../data' \n",
    "    \n",
    "# Output directories\n",
    "logs_dir = '../logs'\n",
    "timestamp = '{:%Y-%m-%dT%H:%M}'.format(datetime.now(gettz(\"Europe/London\")))\n",
    "logs_dir = logs_dir +'/' + timestamp\n",
    "\n",
    "if 'private' in flist[0] and 'correct_plus' in flist[0]:\n",
    "    do_end_test = True\n",
    "else:\n",
    "    do_end_test = False\n",
    "    \n",
    "def readucr(filename):\n",
    "    ''' Load a dataset from a file in UCR format\n",
    "    space delimited, class labels in the first column.\n",
    "    Returns\n",
    "    X : DNN input data\n",
    "    Y : class labels\n",
    "    '''\n",
    "    data = np.loadtxt(Path(filename))\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = flist[0]\n",
    "x_train, y_train = readucr(fdir+'/'+fname+'/'+fname+'_TRAIN.txt')\n",
    "x_test, y_test = readucr(fdir+'/'+fname+'/'+fname+'_TEST.txt')\n",
    "\n",
    "nb_classes = 2\n",
    "y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
    "y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)\n",
    "    \n",
    "x_train_mean = x_train.mean()\n",
    "x_train_std = x_train.std()\n",
    "x_train = (x_train - x_train_mean)/(x_train_std) \n",
    "x_test = (x_test - x_train_mean)/(x_train_std)\n",
    "\n",
    "print('Number of training samples of class 0', (y_train == 0).sum())\n",
    "print('Number of training samples of class 1', (y_train == 1).sum())\n",
    "print('Number of test samples of class 0', (y_test == 0).sum())\n",
    "print('Number of test samples of class 1', (y_test == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit classifier (single train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric='euclidean') # minkowski\n",
    "neigh.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "acc_calc = (cm[0][0]+cm[1][1])/(cm.sum())\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Pred', y_pred[:20])\n",
    "print('True', y_test.astype(int))\n",
    "print(cm)\n",
    "print('Calculated accuracy:',acc_calc)\n",
    "print('Normalised confusion matrix:\\n', cm_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_end_test:\n",
    "    other = fname+'_END_TEST' #_dog_incorrect' # 'private_dog0_correct_plus_END_TEST'\n",
    "    datadir = fdir+'/'+fname\n",
    "    print('Testing on:', datadir+'/'+other+'.txt')\n",
    "    x_other, y_other = readucr(datadir+'/'+other+'.txt')\n",
    "    y_other_pred = neigh.predict(x_other)\n",
    "\n",
    "    # Results\n",
    "    cm = confusion_matrix(y_other, y_other_pred, labels=[1,0])\n",
    "    acc_calc = (cm[0][0]+cm[1][1])/(cm.sum())\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print('KNN cm\\n', cm)\n",
    "    print('KNN cm_norm\\n', cm_norm)\n",
    "    print('KNN acc', acc_calc)\n",
    "\n",
    "    # Get dog result\n",
    "    meta = pd.read_csv(datadir+'/'+other+'_meta.txt', sep=',', parse_dates=['date'])\n",
    "    cm = confusion_matrix(y_other, meta['dog_pred'], labels=[1,0])\n",
    "    dog_acc = (cm[0][0]+cm[1][1])/(cm.sum())\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print('Dog cm\\n', cm)\n",
    "    print('Dog cm_norm\\n', cm_norm)\n",
    "    print('Dog acc', dog_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation setup\n",
    "if k > 1:\n",
    "    x_all = np.concatenate((x_train, x_test), axis=0)\n",
    "    y_all = np.concatenate((y_train, y_test), axis=0)\n",
    "    kfold = RepeatedStratifiedKFold(n_splits=k, n_repeats=m, random_state=k_fold_seed)\n",
    "    scores = list()\n",
    "    other_scores = list() # accuracy on the other dataset, the realistic dataset\n",
    "    for train, test in kfold.split(x_all, y_all):\n",
    "        x_train, y_train, x_test, y_test = x_all[train], y_all[train], x_all[test], y_all[test]\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        neigh.fit(x_train, y_train)\n",
    "        scores.append(neigh.score(x_test, y_test))\n",
    "        if do_end_test:\n",
    "            other_scores.append(neigh.score(x_other, y_other))\n",
    "    print(scores)\n",
    "    print('Estimated Accuracy and sample std dev:')\n",
    "    print(np.mean(scores))\n",
    "    print(np.std(scores, ddof=1))\n",
    "    \n",
    "    if do_end_test:\n",
    "        print(other_scores)\n",
    "        print('Estimated Accuracy and sample std dev on realistic dataset:')\n",
    "        print(np.mean(other_scores))\n",
    "        print(np.std(other_scores, ddof=1))\n",
    "else:\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    neigh.fit(x_train, y_train)\n",
    "    print('Accuracy', neigh.score(x_test, y_test))\n",
    "    \n",
    "# Save the result to file\n",
    "Path(logs_dir+'/'+fname).mkdir(parents=True, exist_ok=True)\n",
    "with open(logs_dir+'/'+fname+'/nearestneighbours_summary.csv', 'w') as f:\n",
    "    w = csv.writer(f, dialect='excel')\n",
    "    for s, o in zip(scores, other_scores):\n",
    "        w.writerow([s, o])\n",
    "    print('Added scores to ', f.name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(scores, columns=['val_acc'])\n",
    "data.boxplot(whis=[2.5,97.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.boxplot(data=data)\n",
    "ax = sns.swarmplot(data=data, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = '../logs/2019-03-17T12:59/private_dog0_correct/devnet_summary.csv'\n",
    "data1 = pd.read_csv(file1, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "name1 = 'dog0_correct'\n",
    "\n",
    "all_data = [data1['val_acc'], data['val_acc']]\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.boxplot(data=all_data)\n",
    "ax = sns.swarmplot(data=all_data, color='black')\n",
    "plt.xticks([0, 1], ['dev_net', 'kNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
