{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP as per Wang, Yan and Oates\n",
    "\n",
    "This software uses cauchyturing/UCR_Time_Series_Classification_Deep_Learning_Baseline\n",
    "\n",
    "See MIT License in https://github.com/cauchyturing/UCR_Time_Series_Classification_Deep_Learning_Baseline README.md\n",
    "\n",
    "Wang, Z., Yan, W. and Oates, T. (2017) ‘Time series classification from scratch with deep neural networks: A strong baseline’, 2017 International Joint Conference on Neural Networks (IJCNN), pp. 1578–1585 Online.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.tz import gettz\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, RepeatedStratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "np.random.seed(813306)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = ['private_correct_plus'] #, ['private_dog0_correct_plus'] # List of dataset directory names. WormsTwoClass Lightning2 Earthquakes GunPoint \n",
    "batch_size = -1 # Set to -1 to use Wang et al settings \n",
    "nb_epochs = 5000 # Wang et al. setting is 5000 but min loss is usually found at <1500\n",
    "k = 3 # For k-fold cross validation. If k=1, the original test-train split is used.\n",
    "m = 4 # Number of repetitions of k-fold cross validation (if k>1).\n",
    "early_stopping = False \n",
    "tensorboard = True # Set to True to write logs for use by TensorBoard\n",
    "k_fold_seed = 87\n",
    "\n",
    "# Output directories\n",
    "logs_dir = '../logs'\n",
    "tensorboard_dir = '../logs/tensorboard'\n",
    "timestamp = '{:%Y-%m-%dT%H:%M}'.format(datetime.now(gettz(\"Europe/London\")))\n",
    "logs_dir = logs_dir +'/' + timestamp\n",
    "tensorboard_dir = tensorboard_dir +'/' + timestamp\n",
    "\n",
    "# Input directory\n",
    "if 'private' in flist[0]:\n",
    "    fdir = '../data/private_data/private_events_dev2' \n",
    "else:\n",
    "    fdir = '../data' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Normalised confusion matrix', save=False):\n",
    "    ''' Plot the normalised confusion matrix\n",
    "    Parameters\n",
    "    cm : array - normalised confusion matrix\n",
    "    Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "    'Confusion Matrix' https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "    '''\n",
    "    classes = ['Positive', 'Negative']\n",
    "    cmap=plt.cm.Blues\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.clim(0, 1)\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('cm_mlpwang.png', bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "def plot_roc(y_true, y_probs, save=False): \n",
    "    ''' Plot ROC and return AUC\n",
    "    Parameters\n",
    "    y_true : vector of true class labels.\n",
    "    y_probs : array of predicted probabilities, one column for each class.\n",
    "    Returns\n",
    "    auc : float\n",
    "    '''\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_probs[:,1])\n",
    "    auc = roc_auc_score(y_true, y_probs[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig('roc_mlwang.png', bbox_inches='tight')\n",
    "    return auc\n",
    "\n",
    "\n",
    "def readucr(filename):\n",
    "    ''' Load a dataset from a file in UCR format\n",
    "    space delimited, class labels in the first column.\n",
    "    Returns\n",
    "    X : DNN input data\n",
    "    Y : class labels\n",
    "    '''\n",
    "    data = np.loadtxt(Path(filename))\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, nb_classes):\n",
    "    num = 500\n",
    "    x = Input(shape=(input_shape))\n",
    "    y = Dropout(0.1,name='WDrop010')(x)\n",
    "    y = Dense(num, activation='relu', name='WDense010')(y)\n",
    "    y = Dropout(0.2,name='WDrop020')(y)\n",
    "    y = Dense(num, activation='relu', name='WDense020')(y)\n",
    "    y = Dropout(0.2,name='WDrop021')(y)\n",
    "    y = Dense(num, activation='relu', name='WDense021')(y)\n",
    "    y = Dropout(0.3,name='WDrop031')(y)\n",
    "    out = Dense(nb_classes, activation='softmax', name='WDense080')(y)\n",
    "    return x, out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(fname, x_train, y_train, x_test, y_test, label=\"0\"):\n",
    "    print('Running dataset', fname)\n",
    "    if batch_size == -1:\n",
    "        batch = int(min(x_train.shape[0]/10, 16)) # Wang et al. setting.\n",
    "    else:\n",
    "        batch=batch_size \n",
    "        \n",
    "    nb_classes = len(np.unique(y_test))\n",
    "     \n",
    "    y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
    "    y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)\n",
    "     \n",
    "    Y_train = utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = utils.to_categorical(y_test, nb_classes)\n",
    "     \n",
    "    x_train_mean = x_train.mean()\n",
    "    x_train_std = x_train.std()\n",
    "    x_train = (x_train - x_train_mean)/(x_train_std) \n",
    "    x_test = (x_test - x_train_mean)/(x_train_std)\n",
    "     \n",
    "    x, y = build_mlp(x_train.shape[1:], nb_classes)\n",
    "    model = Model(x, y)\n",
    "    #print(model.summary())\n",
    "    Path(logs_dir+'/'+fname).mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "    optimizer = keras.optimizers.Adadelta(rho=0.95, epsilon=1e-8) # paper specifies rho and epsilon, although GitHub code does not. \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
    "                      patience=200, min_lr=0.1)\n",
    "    callbacks = [reduce_lr]\n",
    "    if tensorboard:\n",
    "        tb_dir = tensorboard_dir+'/'+fname+'_'+label\n",
    "        Path(tb_dir).mkdir(parents=True, exist_ok=True) \n",
    "        print('Tensorboard logs in', tb_dir)\n",
    "        callbacks.append(keras.callbacks.TensorBoard(log_dir=tb_dir, histogram_freq=0))\n",
    "  \n",
    "    start = time.time()\n",
    "    print(x_test[:10])\n",
    "    print(Y_test[:10])\n",
    "    hist = model.fit(x_train, Y_train, batch_size=batch, epochs=nb_epochs,\n",
    "             verbose=1, validation_data=(x_test, Y_test), callbacks=callbacks)\n",
    "    end = time.time()\n",
    "    log = pd.DataFrame(hist.history) \n",
    "    \n",
    "    # Print results\n",
    "    duration_seconds = round(end-start)\n",
    "    duration_minutes = str(round((end-start)/60))\n",
    "    print('Training complete on', fname, 'Duration:', duration_seconds, 'secs; about', duration_minutes, 'minutes.')\n",
    "    \n",
    "    # Print and save results. Print the testing results which has the lowest training loss.\n",
    "    print('Selected the test result with the lowest training loss. Loss and validation accuracy are -')\n",
    "    idx = log['loss'].idxmin()\n",
    "    loss = log.loc[idx]['loss']\n",
    "    val_acc = log.loc[idx]['val_acc']\n",
    "    epoch = idx + 1\n",
    "    print(loss, val_acc, 'at index', str(idx), ' (epoch ', str(epoch), ')')   \n",
    "    summary = '|' + label + '  |'+str(loss)+'  |'+str(val_acc)+' |'+str(epoch)+' |'+ duration_minutes + 'mins  |'\n",
    "    summary_csv = label+','+str(loss)+','+str(val_acc)+','+str(epoch)+','+ duration_minutes \n",
    "    \n",
    "    # Save summary file and log file.\n",
    "    print('Tensorboard logs in', tb_dir)\n",
    "    with open(logs_dir+'/'+fname+'/mlpwang_summary.csv', 'a+') as f:\n",
    "        f.write(summary_csv)\n",
    "        f.write('\\n')\n",
    "        print('Added summary row to ', logs_dir+'/'+fname+'/mlpwang_summary.csv')  \n",
    "    print('Saving logs to',logs_dir+'/'+fname+'/history_'+label+'.csv')\n",
    "    log.to_csv(logs_dir+'/'+fname+'/history_'+label+'.csv')\n",
    "    \n",
    "    return summary, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for each in flist:\n",
    "    fname = each\n",
    "    x_train, y_train = readucr(fdir+'/'+fname+'/'+fname+'_TRAIN.txt')\n",
    "    x_test, y_test = readucr(fdir+'/'+fname+'/'+fname+'_TEST.txt')\n",
    "    # k-fold cross validation setup\n",
    "    if k > 1:\n",
    "        x_all = np.concatenate((x_train, x_test), axis=0)\n",
    "        y_all = np.concatenate((y_train, y_test), axis=0)\n",
    "        kfold = RepeatedStratifiedKFold(n_splits=k, n_repeats=m, random_state=k_fold_seed)\n",
    "        count = 0\n",
    "        for train, test in kfold.split(x_all, y_all):\n",
    "            x_train, y_train, x_test, y_test = x_all[train], y_all[train], x_all[test], y_all[test]\n",
    "            summary, model = train_model(fname, x_train, y_train, x_test, y_test, str(count))\n",
    "            results.append(summary)\n",
    "            count = count + 1\n",
    "    else:\n",
    "        summary, model = train_model(fname, x_train, y_train, x_test, y_test)\n",
    "        results.append(summary)\n",
    "        \n",
    "print('DONE')\n",
    "print(fname, timestamp)\n",
    "print('train:test', y_train.shape[0], y_test.shape[0])\n",
    "for each in results:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print when done\n",
    "print('Done at:' , '{:%Y-%m-%dT%H:%M}'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use trained model (after all epochs) to make predictions\n",
    "do_print = True\n",
    "x_input = x_test\n",
    "y_input = y_test\n",
    "y_input = y_input - y_input.min()\n",
    "x_train_mean = x_train.mean()\n",
    "x_train_std = x_train.std()\n",
    "x_input = (x_input - x_train_mean)/(x_train_std)\n",
    "nb_classes = len(np.unique(y_input))\n",
    "y_input = (y_input - y_input.min())/(y_input.max()-y_input.min())*(nb_classes-1)\n",
    "# Class balance\n",
    "n0 = (y_input == 0).sum()\n",
    "n1 = (y_input == 1).sum()\n",
    "# Calculate model prediction\n",
    "y_probs = model.predict_on_batch(x_input)\n",
    "y_class = y_probs.argmax(axis=1)\n",
    "cm = confusion_matrix(y_input, y_probs.argmax(axis=1), labels=[1,0])\n",
    "acc_calc = (cm[0][0]+cm[1][1])/(cm.sum())\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "if do_print:\n",
    "    print('Predicted class probabilities:\\n', y_probs[:5,:])\n",
    "    print('Pred', y_class[:20])\n",
    "    print('True', y_input[:20].astype(int))\n",
    "    print(cm)\n",
    "    print('Calculated accuracy:',acc_calc)\n",
    "    print('Class balance in test set:', n0, 'to', n1, 'i.e.', n0/(n0+n1))\n",
    "    print('Normalised confusion matrix:\\n', cm_norm)\n",
    "title = 'Normalised confusion matrix'\n",
    "plot_confusion_matrix(cm_norm, title=title, save=True)\n",
    "\n",
    "# ROC and AUC\n",
    "auc = plot_roc(y_input, y_probs)\n",
    "print('AUC:', auc)\n",
    "\n",
    "report = classification_report(y_input, y_class)\n",
    "print('\\n', report)\n",
    "print('\\nmicro av - averaging the total true positives, false negatives and false positives')\n",
    "print('macro av - averaging the unweighted mean per label')\n",
    "print('weighted av - averaging the support-weighted mean per label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =  logs_dir+'/'+fname+'/mlpwang_summary.csv'\n",
    "data = pd.read_csv(file, header=None, names=['run','loss','val_acc','epoch','time'])\n",
    "accuracy = data['val_acc']\n",
    "print(file)\n",
    "print('Accuracy mean, sample std dev and 95% confidence level is', accuracy.mean(), accuracy.std(), accuracy.std()*2.262)\n",
    "print('95% quantile interval is', accuracy.quantile(0.0025), 'to', accuracy.quantile(0.975))\n",
    "data.boxplot(column=['val_acc'], whis=[2.5,97.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = fname+'_END_TEST' #_dog_incorrect' # 'private_dog0_correct_plus_END_TEST'\n",
    "datadir = fdir+'/'+fname\n",
    "print('Testing on:', datadir+'/'+other+'.txt')\n",
    "print('Testing model that has validation accuracy', accuracy[9])\n",
    "\n",
    "x_other, y_other = readucr(datadir+'/'+other+'.txt')\n",
    "\n",
    "x_input = x_other\n",
    "y_input = y_other\n",
    "y_input = y_input - y_input.min()\n",
    "x_train_mean = x_train.mean()\n",
    "x_train_std = x_train.std()\n",
    "x_input = (x_input - x_train_mean)/(x_train_std)\n",
    "nb_classes = len(np.unique(y_input))\n",
    "y_input = (y_input - y_input.min())/(y_input.max()-y_input.min())*(nb_classes-1)\n",
    "# Calculate model prediction\n",
    "y_probs = model.predict_on_batch(x_input)\n",
    "y_class = y_probs.argmax(axis=1)\n",
    "cm = confusion_matrix(y_input, y_probs.argmax(axis=1), labels=[1,0])\n",
    "acc_calc = (cm[0][0]+cm[1][1])/(cm.sum())\n",
    "print(cm)\n",
    "print('accuracy', acc_calc)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "title = 'Normalised confusion matrix on end test dataset'\n",
    "plot_confusion_matrix(cm_norm, title=title, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
