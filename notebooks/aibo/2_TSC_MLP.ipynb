{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series classification - MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Python packages\n",
    "Import the Python packages that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# General settings\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_web = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_web:\n",
    "    url = 'https://raw.githubusercontent.com/Withington/deepscent/master/data/SonyAIBORobotSurface1_IoC/SonyAIBORobotSurface1_IoC_DEV.txt'\n",
    "    robot_df = pd.read_csv(url, sep='\\t', header=None)\n",
    "    print('Loaded from', url)\n",
    "    robot_data = robot_df.values\n",
    "else:\n",
    "    data_dir = '../../data'\n",
    "    data_name = 'SonyAIBORobotSurface1_IoC'\n",
    "    data_filename = data_dir+'/'+data_name+'/'+data_name+'_DEV.txt'\n",
    "    robot_data = np.loadtxt(Path(data_filename))\n",
    "    print('Loaded from', data_filename)\n",
    "print('The shape of robot_data is', robot_data.shape)\n",
    "print('robot_data:', robot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = robot_data[:,0]\n",
    "x_dev = robot_data[:,1:]\n",
    "print('The shape of x_dev is', x_dev.shape)\n",
    "print('The shape of y_dev is', y_dev.shape)\n",
    "\n",
    "# Change from classes 1 and 2 to classes 0 and 1\n",
    "y_dev = (y_dev - y_dev.min())/(y_dev.max()-y_dev.min())\n",
    "\n",
    "print('Number of samples of class 0', (y_dev == 0).sum())\n",
    "print('Number of samples of class 1', (y_dev == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the development dataset into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of samples of class 0', (y_dev == 0).sum())\n",
    "print('Number of samples of class 1', (y_dev == 1).sum())\n",
    "y_dev_df = pd.DataFrame(y_dev)\n",
    "y_dev_df[0].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_dev, y_dev, test_size=100, random_state=21, stratify=y_dev)\n",
    "\n",
    "print('The shape of train_data is', x_train.shape)\n",
    "print('The shape of test_data is', x_test.shape)\n",
    "print('Training data:')\n",
    "print('Number of samples of class 0', (y_train == 0).sum())\n",
    "print('Number of samples of class 1', (y_train == 1).sum())\n",
    "print('Test data:')\n",
    "print('Number of samples of class 0', (y_test == 0).sum())\n",
    "print('Number of samples of class 1', (y_test == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = x_train.mean()\n",
    "x_train_std = x_train.std()\n",
    "print('x_train_mean', x_train_mean)\n",
    "print('x_train_std', x_train_std)\n",
    "\n",
    "do_standardise = False\n",
    "if do_standardise:\n",
    "    x_train = (x_train - x_train_mean)/(x_train_std) \n",
    "    x_test = (x_test - x_train_mean)/(x_train_std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_a = 0 ### CHANGE PARAMETER HERE ###\n",
    "sample_b = 4 ### CHANGE PARAMETER HERE ###\n",
    "plt.plot(x_train[sample_a], label='category'+str(y_train[sample_a]))\n",
    "plt.plot(x_train[sample_b], label='category'+str(y_train[sample_b]))\n",
    "plt.legend(loc='upper right', frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP 1\n",
    "Create an multilayer perceptron (MLP). This first MLP is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(input_shape), name='InputLayer')\n",
    "# Layer 1\n",
    "y = Dense(16, activation='relu', name='Layer010Dense')(x) ### CHANGE PARAMETER HERE ###\n",
    "# Layer 2\n",
    "y = Dense(8, activation='relu', name='Layer020Dense')(y) ### CHANGE PARAMETER HERE ###\n",
    "# Output layer\n",
    "out = Dense(1, activation='sigmoid', name='OutputLayer')(y)\n",
    "\n",
    "# Build model\n",
    "model_mlp1 = Model(x, out)\n",
    "print(model_mlp1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the number of parameters\n",
    "TODO - exercise around the calculation that arrives at the number of parameters in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(70*16+16)\n",
    "print(16*8+8)\n",
    "print(8+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select an optimizer and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "model_mlp1.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# TODO - can we access TensorBoard on colab? If so, add tensorboard callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "hist = model_mlp1.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "end = time.time()\n",
    "log = pd.DataFrame(hist.history) \n",
    "print('Training complete in', round(end-start), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The first five rows in the log are')\n",
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The last five rows in the log are')\n",
    "log.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log[['loss', 'val_loss']].plot()\n",
    "# TODO add axes labels, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log[['acc', 'val_acc']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions using MLP 1\n",
    "Classify the data using MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_mlp1.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Validation accuracy is', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probability = model_mlp1.predict_on_batch(x_test)\n",
    "y_predicted_class = np.round(y_probability).flatten()\n",
    "print('Some of the test results:')\n",
    "print('True', y_test[:23])\n",
    "print('Pred', y_predicted_class[:23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 3\n",
    "print('The probability that sample', sample, 'belongs to class 1 is', y_probability[sample][0])\n",
    "print('The model classifies sample', sample, 'as class', y_predicted_class[sample])\n",
    "print('The true class of sample', sample, 'is class', y_test[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_a = 0 ### CHANGE PARAMETER HERE ###\n",
    "sample_b = 3 ### CHANGE PARAMETER HERE ###\n",
    "plt.plot(x_test[sample_a], label='True:'+str(y_test[sample_a])+' Pred:'+str(y_predicted_class[sample_a]))\n",
    "plt.plot(x_test[sample_b], label='True:'+str(y_test[sample_b])+' Pred:'+str(y_predicted_class[sample_b]))\n",
    "plt.legend(loc='upper right', frameon=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
