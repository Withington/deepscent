{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series classification - cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Python packages\n",
    "Import the Python packages that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# General settings\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_web = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the development dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_web:\n",
    "    url = 'https://raw.githubusercontent.com/Withington/deepscent/master/data/SonyAIBORobotSurface1_IoC/SonyAIBORobotSurface1_IoC_DEV.txt'\n",
    "    robot_df = pd.read_csv(url, sep='\\t', header=None)\n",
    "    print('Loaded from', url)\n",
    "    robot_data = robot_df.values\n",
    "else:\n",
    "    data_dir = '../../data'\n",
    "    data_name = 'SonyAIBORobotSurface1_IoC'\n",
    "    data_filename = data_dir+'/'+data_name+'/'+data_name+'_DEV.txt'\n",
    "    robot_data = np.loadtxt(Path(data_filename))\n",
    "    print('Loaded from', data_filename)\n",
    "\n",
    "y_dev = robot_data[:,0]\n",
    "x_dev = robot_data[:,1:]\n",
    "print('The shape of x_dev is', x_dev.shape)\n",
    "print('The shape of y_dev is', y_dev.shape)\n",
    "\n",
    "# Change from classes 1 and 2 to classes 0 and 1\n",
    "y_dev = (y_dev - y_dev.min())/(y_dev.max()-y_dev.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP 2\n",
    "This time we will create a function that builds our model.\n",
    "\n",
    "\n",
    "TODO - remove dropout at this stage and make introduction of dropout a separate exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    x = Input(shape=(x_dev.shape[1:]), name='InputLayer')\n",
    "    ### CHANGE PARAMETERS HERE ###\n",
    "    y = Dense(16, activation='relu', name='Layer010Dense')(x) \n",
    "    y = Dense(16, activation='relu', name='Layer020Dense')(y)\n",
    "    y = Dense(16, activation='relu', name='Layer030Dense')(y)\n",
    "    ### END OF CHANGE PARAMETERS ###\n",
    "    out = Dense(1, activation='sigmoid', name='OutputLayer')(y)\n",
    "\n",
    "    # Build model and compile the model\n",
    "    model = Model(x, out)\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Train the model once to get a feel for how many epochs are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_dev, y_dev, test_size=100, random_state=21, stratify=y_dev)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "batch_size = 5\n",
    "epochs = 50\n",
    "start = time.time()\n",
    "hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "                 validation_data=(x_test, y_test), verbose=1)\n",
    "end = time.time()\n",
    "log = pd.DataFrame(hist.history) \n",
    "print('Training complete in', round(end-start), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log[['acc', 'val_acc']].plot()\n",
    "result = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Validation accuracy is', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE PARAMETERS HERE ###\n",
    "k = 3 \n",
    "m = 5 \n",
    "batch_size = 10\n",
    "epochs = 30\n",
    "### END OF CHANGE PARAMETERS ###\n",
    "\n",
    "kfold = RepeatedStratifiedKFold(n_splits=k, n_repeats=m, random_state=76)\n",
    "count = 0\n",
    "val_acc = list()\n",
    "start = time.time()\n",
    "for train, test in kfold.split(x_dev, y_dev):\n",
    "    x_train, y_train, x_test, y_test = x_dev[train], y_dev[train], x_dev[test], y_dev[test]\n",
    "    # Normalise the data\n",
    "    x_train_mean = x_train.mean()\n",
    "    x_train_std = x_train.std()\n",
    "    x_train = (x_train - x_train_mean)/(x_train_std) \n",
    "    x_test = (x_test - x_train_mean)/(x_train_std)\n",
    "    # Build and train a model\n",
    "    model = build_model()\n",
    "    fold_start = time.time()\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "    fold_end = time.time()\n",
    "    log = pd.DataFrame(hist.history) \n",
    "    print('Training of iteration', count, 'complete in', round(fold_end-fold_start), 'seconds')\n",
    "    val_acc.append(log.iloc[-1]['val_acc'])\n",
    "    count = count + 1\n",
    "\n",
    "end = time.time()\n",
    "val_acc = pd.DataFrame(val_acc, columns=['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_acc)\n",
    "print(m, 'repeats of', k, '-fold cross validation completed in', round(end-start), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the k-fold cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=val_acc)\n",
    "ax = sns.swarmplot(data=val_acc, color='black')\n",
    "print('Validation accuracy mean and sample standard deviation', val_acc['val_acc'].mean(), val_acc['val_acc'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed - GPU\n",
    "Using a GPU can speed up calculations. However, it can take longer to transfer the data to the GPU.\n",
    "\n",
    "You are more likely to see a speed-up if batch size is large. As you increase batch size, check that valuation accuracy does not deteriorate.\n",
    "\n",
    "To use a GPU in colab select Edit - Notebook settings and then set Hardware accelerator to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if you are using a GPU.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "print('Found a GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalisation - dropout\n",
    "Try adding dropout layers to your model. An example of such a model is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_dropout():\n",
    "    x = Input(shape=(x_dev.shape[1:]), name='InputLayer')\n",
    "    ### CHANGE PARAMETERS HERE ###\n",
    "    y = Dropout(0.1,name='InputLayerDropout')(x)\n",
    "    y = Dense(16, activation='relu', name='Layer010Dense')(y) \n",
    "    y = Dropout(0.2,name='Layer010Dropout')(y)\n",
    "    y = Dense(16, activation='relu', name='Layer020Dense')(y)\n",
    "    y = Dropout(0.2,name='Layer020Dropout')(y)\n",
    "    y = Dense(16, activation='relu', name='Layer030Dense')(y)\n",
    "    y = Dropout(0.3,name='Layer030Dropout')(y)\n",
    "    ### END OF CHANGE PARAMETERS ###\n",
    "    out = Dense(1, activation='sigmoid', name='OutputLayer')(y)\n",
    "\n",
    "    # Build model and compile the model\n",
    "    model = Model(x, out)\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
