{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.tz import gettz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(757566)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'GunPoint' # private_dog0_correct_plus\n",
    "log_to_file = True\n",
    "\n",
    "tensorboard_dir = '../logs/tensorboard'\n",
    "logs_dir = '../logs'\n",
    "timestamp = '{:%Y-%m-%dT%H:%M}'.format(datetime.now(gettz(\"Europe/London\")))\n",
    "logs_dir = logs_dir +'/' + timestamp\n",
    "tensorboard_dir = tensorboard_dir +'/' + timestamp\n",
    "if 'private' in fname:\n",
    "    fdir = '../data/private_data/private_events_dev2' \n",
    "else:\n",
    "    fdir = '../data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    ''' Load a dataset from a file in UCR format\n",
    "    space delimited, class labels in the first column.\n",
    "    Returns\n",
    "    X : DNN input data\n",
    "    Y : class labels\n",
    "    '''\n",
    "    data = np.loadtxt(Path(filename))\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid search adapted from Machine Learning Mastery\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])   \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_functional_model():\n",
    "    # create model\n",
    "    drop = 0.2\n",
    "    num = 64\n",
    "    l2 = 0.1\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(X_SHAPE))\n",
    "    y = Dropout(drop,name='Drop010')(x)\n",
    "    y = Dense(num, kernel_regularizer=regularizers.l2(l2), activation='relu', name='Dense010')(y)\n",
    "    y = Dropout(drop,name='Drop081')(y)\n",
    "    out = Dense(nb_classes-1, activation='sigmoid', name='Dense080')(y)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_fcn(input_shape=(150,1), num_features=100, filter_size=10, pooling_size=3, dropout=0.5):\n",
    "    ''' Create FCN model '''\n",
    "    num_features0 = num_features\n",
    "    num_features1 = math.floor(1.5 * num_features)\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(x)\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.MaxPooling1D(pooling_size)(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    full = keras.layers.GlobalAveragePooling1D()(conv_x)\n",
    "    y = Dropout(dropout,name='Dropout')(full)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(full)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_fcn_simple():\n",
    "    ''' Create FCN model '''\n",
    "    input_shape=(150,1)\n",
    "    num_features=100\n",
    "    filter_size=10\n",
    "    pooling_size=3\n",
    "    dropout=0.5\n",
    "    num_features0 = num_features\n",
    "    num_features1 = math.floor(1.5 * num_features)\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(x)\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.MaxPooling1D(pooling_size)(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    full = keras.layers.GlobalAveragePooling1D()(conv_x)\n",
    "    y = Dropout(dropout,name='Dropout')(full)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(full)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(y):\n",
    "    nb_classes = 2\n",
    "    y = (y - y.min())/(y.max()-y.min())*(nb_classes-1)\n",
    "    Y = utils.to_categorical(y, nb_classes)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1)\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 1s 11ms/sample - loss: 0.7016 - acc: 0.5075\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 0s 420us/sample - loss: 0.6966 - acc: 0.5113\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 0s 447us/sample - loss: 0.6945 - acc: 0.5113\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 0s 457us/sample - loss: 0.6892 - acc: 0.5113\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 0s 448us/sample - loss: 0.6887 - acc: 0.5752\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 0s 480us/sample - loss: 0.6775 - acc: 0.5789\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 0s 487us/sample - loss: 0.6707 - acc: 0.5226\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 0s 439us/sample - loss: 0.6815 - acc: 0.5564\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 0s 460us/sample - loss: 0.6672 - acc: 0.6053\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 0s 433us/sample - loss: 0.6407 - acc: 0.5150\n",
      "67/67 [==============================] - 1s 19ms/sample - loss: 0.5862 - acc: 0.8731\n",
      "133/133 [==============================] - 0s 162us/sample - loss: 0.5907 - acc: 0.8421\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 2s 12ms/sample - loss: 0.7034 - acc: 0.5188\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 0s 431us/sample - loss: 0.6917 - acc: 0.4887\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 0s 468us/sample - loss: 0.6903 - acc: 0.4812\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 0s 482us/sample - loss: 0.6762 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 0s 449us/sample - loss: 0.6468 - acc: 0.6541\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 0s 440us/sample - loss: 0.6003 - acc: 0.6617\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 0s 458us/sample - loss: 0.5625 - acc: 0.6842\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 0s 465us/sample - loss: 0.5783 - acc: 0.6579\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 0s 484us/sample - loss: 0.5916 - acc: 0.6504\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 0s 454us/sample - loss: 0.4898 - acc: 0.7744\n",
      "67/67 [==============================] - 1s 21ms/sample - loss: 0.5478 - acc: 0.6343\n",
      "133/133 [==============================] - 0s 189us/sample - loss: 0.5144 - acc: 0.6955\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 2s 11ms/sample - loss: 0.6936 - acc: 0.4888\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 0s 430us/sample - loss: 0.6936 - acc: 0.5075\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 0s 449us/sample - loss: 0.6880 - acc: 0.5075\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 0s 470us/sample - loss: 0.6732 - acc: 0.7164\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 0s 524us/sample - loss: 0.6269 - acc: 0.7537\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 0s 535us/sample - loss: 0.5365 - acc: 0.7836\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 0s 543us/sample - loss: 0.4426 - acc: 0.7948\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 0s 538us/sample - loss: 0.4240 - acc: 0.7612\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 0s 442us/sample - loss: 0.3459 - acc: 0.8545\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 0s 461us/sample - loss: 0.2363 - acc: 0.9440\n",
      "66/66 [==============================] - 1s 21ms/sample - loss: 0.2124 - acc: 0.9394\n",
      "134/134 [==============================] - 0s 212us/sample - loss: 0.1874 - acc: 0.9739\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 2s 12ms/sample - loss: 0.7112 - acc: 0.4737\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 0s 348us/sample - loss: 0.6929 - acc: 0.5113\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 0s 347us/sample - loss: 0.6908 - acc: 0.6241\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 0s 330us/sample - loss: 0.6876 - acc: 0.6053\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 0s 349us/sample - loss: 0.6804 - acc: 0.6692\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 0s 344us/sample - loss: 0.6769 - acc: 0.4887\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 0s 309us/sample - loss: 0.6805 - acc: 0.5038\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 0s 273us/sample - loss: 0.6471 - acc: 0.6391\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 0s 306us/sample - loss: 0.6335 - acc: 0.6391\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 0s 291us/sample - loss: 0.6203 - acc: 0.6241\n",
      "67/67 [==============================] - 1s 21ms/sample - loss: 0.5831 - acc: 0.6791\n",
      "133/133 [==============================] - 0s 150us/sample - loss: 0.5910 - acc: 0.6504\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 2s 11ms/sample - loss: 0.6913 - acc: 0.5113\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 0s 291us/sample - loss: 0.6934 - acc: 0.4774\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 0s 290us/sample - loss: 0.6911 - acc: 0.4812\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 0s 291us/sample - loss: 0.6954 - acc: 0.4812\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 0s 293us/sample - loss: 0.6797 - acc: 0.4962\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 0s 299us/sample - loss: 0.6590 - acc: 0.6729\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 0s 298us/sample - loss: 0.6259 - acc: 0.6316\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 0s 313us/sample - loss: 0.5798 - acc: 0.6880\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 0s 304us/sample - loss: 0.5506 - acc: 0.6504\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 0s 332us/sample - loss: 0.5060 - acc: 0.7556\n",
      "67/67 [==============================] - 1s 20ms/sample - loss: 0.6965 - acc: 0.5373\n",
      "133/133 [==============================] - 0s 200us/sample - loss: 0.5447 - acc: 0.6692\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 2s 12ms/sample - loss: 0.7211 - acc: 0.4925\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 0s 270us/sample - loss: 0.6931 - acc: 0.4925\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 0s 273us/sample - loss: 0.6917 - acc: 0.4925\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 0s 259us/sample - loss: 0.6907 - acc: 0.4925\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 0s 276us/sample - loss: 0.6891 - acc: 0.5075\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 0s 306us/sample - loss: 0.6864 - acc: 0.6754\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 0s 332us/sample - loss: 0.6793 - acc: 0.6045\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 0s 317us/sample - loss: 0.6634 - acc: 0.7313\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 0s 321us/sample - loss: 0.6442 - acc: 0.7164\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 0s 331us/sample - loss: 0.6139 - acc: 0.7351\n",
      "66/66 [==============================] - 1s 22ms/sample - loss: 0.6151 - acc: 0.5000\n",
      "134/134 [==============================] - 0s 86us/sample - loss: 0.6138 - acc: 0.5485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 2s 9ms/sample - loss: 0.7083 - acc: 0.4800\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 404us/sample - loss: 0.6867 - acc: 0.5500\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 419us/sample - loss: 0.6768 - acc: 0.4825\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 396us/sample - loss: 0.6689 - acc: 0.5950\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 467us/sample - loss: 0.6068 - acc: 0.7375\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 434us/sample - loss: 0.5619 - acc: 0.6775\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 451us/sample - loss: 0.4913 - acc: 0.7475\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 438us/sample - loss: 0.3750 - acc: 0.8050\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 432us/sample - loss: 0.2515 - acc: 0.9050\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 449us/sample - loss: 0.2489 - acc: 0.8750\n",
      "Best: 0.815000 using {'batch_size': 32}\n",
      "0.815000 (0.131048) with: {'batch_size': 32}\n",
      "0.572500 (0.077178) with: {'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "#dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "#X = dataset[:,0:8]\n",
    "#Y = dataset[:,8]\n",
    "\n",
    "x_train, y_train = readucr(fdir+'/'+fname+'/'+fname+'_TRAIN.txt')\n",
    "x_test, y_test = readucr(fdir+'/'+fname+'/'+fname+'_TEST.txt')\n",
    "X = np.concatenate((x_train, x_test), axis=0)\n",
    "Y = np.concatenate((y_train, y_test), axis=0)\n",
    "X = X.reshape(X.shape + (1,))\n",
    "input_shape = X.shape[1:]\n",
    "print(input_shape)\n",
    "Y = prepare_data(Y)\n",
    "\n",
    "# Add callbacks\n",
    "callbacks = []\n",
    "tb_dir = tensorboard_dir+'/'+fname\n",
    "Path(tb_dir).mkdir(parents=True, exist_ok=True) \n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir=tb_dir, histogram_freq=0))\n",
    "\n",
    "\n",
    "\n",
    "# create model\n",
    "#model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "#model = KerasClassifier(build_fn=create_functional_model, verbose=1,\n",
    "#                        batch_size=32\n",
    "#                        callbacks=callbacks)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "num_features = [32] # [32, 64]\n",
    "filter_size = [4] # [4, 16]\n",
    "pooling_size = [4] # [4, 8]\n",
    "dropout = [0.5]\n",
    "#param_grid = dict(num_features=num_features, filter_size=filter_size, pooling_size=pooling_size, dropout=dropout)\n",
    "param_grid = dict(pooling_size=pooling_size)\n",
    "\n",
    "mode = 1\n",
    "if mode == 0:\n",
    "    model = KerasClassifier(build_fn=create_fcn, \n",
    "                            input_shape=input_shape,\n",
    "                            num_features=32, filter_size=4,\n",
    "                            dropout=0.5,\n",
    "                            batch_size=batch_size, epochs=epochs,\n",
    "                           verbose=1)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, error_score=0) #fit_params={'callbacks': callbacks})\n",
    "    grid_result = grid.fit(X, Y)\n",
    "elif mode == 1:\n",
    "    param_grid = dict(batch_size=[32, 64])\n",
    "    model = KerasClassifier(build_fn=create_fcn_simple, \n",
    "                               epochs=epochs,\n",
    "                               verbose=1)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, error_score=0) #fit_params={'callbacks': callbacks})\n",
    "    grid_result = grid.fit(X, Y)\n",
    "else:\n",
    "    model = create_fcn(input_shape=input_shape,\n",
    "                        num_features=32, filter_size=4, pooling_size=4,\n",
    "                        dropout=0.5)\n",
    "    model.fit(X, Y, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.831505</td>\n",
       "      <td>5.597483</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.837158</td>\n",
       "      <td>32</td>\n",
       "      <td>{'batch_size': 32}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.873134</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>0.695489</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.973881</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.065676</td>\n",
       "      <td>0.131048</td>\n",
       "      <td>0.113707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.255438</td>\n",
       "      <td>5.996495</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>0.622685</td>\n",
       "      <td>64</td>\n",
       "      <td>{'batch_size': 64}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.679105</td>\n",
       "      <td>0.650376</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.669173</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.548507</td>\n",
       "      <td>0.181910</td>\n",
       "      <td>0.142516</td>\n",
       "      <td>0.077178</td>\n",
       "      <td>0.053010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      20.831505         5.597483           0.8150          0.837158   \n",
       "1      21.255438         5.996495           0.5725          0.622685   \n",
       "\n",
       "  param_batch_size              params  rank_test_score  split0_test_score  \\\n",
       "0               32  {'batch_size': 32}                1           0.873134   \n",
       "1               64  {'batch_size': 64}                2           0.679105   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.842105           0.634328            0.695489   \n",
       "1            0.650376           0.537313            0.669173   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.939394            0.973881      0.289463        0.065676   \n",
       "1           0.500000            0.548507      0.181910        0.142516   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.131048         0.113707  \n",
       "1        0.077178         0.053010  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_\n",
    "cv = pd.DataFrame(grid_result.cv_results_)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
