{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.tz import gettz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(757566)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'GunPoint' # private_dog0_correct_plus\n",
    "log_to_file = True\n",
    "\n",
    "tensorboard_dir = '../logs/tensorboard'\n",
    "logs_dir = '../logs'\n",
    "timestamp = '{:%Y-%m-%dT%H:%M}'.format(datetime.now(gettz(\"Europe/London\")))\n",
    "logs_dir = logs_dir +'/' + timestamp\n",
    "tensorboard_dir = tensorboard_dir +'/' + timestamp\n",
    "if 'private' in fname:\n",
    "    fdir = '../data/private_data/private_events_dev2' \n",
    "else:\n",
    "    fdir = '../data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    ''' Load a dataset from a file in UCR format\n",
    "    space delimited, class labels in the first column.\n",
    "    Returns\n",
    "    X : DNN input data\n",
    "    Y : class labels\n",
    "    '''\n",
    "    data = np.loadtxt(Path(filename))\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid search adapted from Machine Learning Mastery\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])   \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_functional_model():\n",
    "    # create model\n",
    "    drop = 0.2\n",
    "    num = 64\n",
    "    l2 = 0.1\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(X_SHAPE))\n",
    "    y = Dropout(drop,name='Drop010')(x)\n",
    "    y = Dense(num, kernel_regularizer=regularizers.l2(l2), activation='relu', name='Dense010')(y)\n",
    "    y = Dropout(drop,name='Drop081')(y)\n",
    "    out = Dense(nb_classes-1, activation='sigmoid', name='Dense080')(y)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_fcn(input_shape=(150,1), num_features=100, filter_size=10, pooling_size=3, dropout=0.5):\n",
    "    ''' Create FCN model '''\n",
    "    num_features0 = num_features\n",
    "    num_features1 = math.floor(1.5 * num_features)\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(x)\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.MaxPooling1D(pooling_size)(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    full = keras.layers.GlobalAveragePooling1D()(conv_x)\n",
    "    y = Dropout(dropout,name='Dropout')(full)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(full)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_fcn_simple():\n",
    "    ''' Create FCN model '''\n",
    "    input_shape=(150,1)\n",
    "    num_features=100\n",
    "    filter_size=10\n",
    "    pooling_size=3\n",
    "    dropout=0.5\n",
    "    num_features0 = num_features\n",
    "    num_features1 = math.floor(1.5 * num_features)\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(x)\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.MaxPooling1D(pooling_size)(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    full = keras.layers.GlobalAveragePooling1D()(conv_x)\n",
    "    y = Dropout(dropout,name='Dropout')(full)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(full)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(y):\n",
    "    nb_classes = 2\n",
    "    y = (y - y.min())/(y.max()-y.min())*(nb_classes-1)\n",
    "    Y = utils.to_categorical(y, nb_classes)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "x_train, y_train = readucr(fdir+'/'+fname+'/'+fname+'_TRAIN.txt')\n",
    "x_test, y_test = readucr(fdir+'/'+fname+'/'+fname+'_TEST.txt')\n",
    "X = np.concatenate((x_train, x_test), axis=0)\n",
    "Y = np.concatenate((y_train, y_test), axis=0)\n",
    "X = X.reshape(X.shape + (1,))\n",
    "input_shape = X.shape[1:]\n",
    "print(input_shape)\n",
    "Y = prepare_data(Y)\n",
    "\n",
    "# Add callbacks\n",
    "callbacks = []\n",
    "tb_dir = tensorboard_dir+'/'+fname\n",
    "Path(tb_dir).mkdir(parents=True, exist_ok=True) \n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir=tb_dir, histogram_freq=0))\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "num_features = [32] # [32, 64]\n",
    "filter_size = [4] # [4, 16]\n",
    "pooling_size = [4] # [4, 8]\n",
    "dropout = 0.5\n",
    "param_grid = dict(num_features=num_features, filter_size=filter_size, pooling_size=pooling_size)\n",
    "\n",
    "# Create model and run the grid search\n",
    "model = KerasClassifier(build_fn=create_fcn, \n",
    "                        input_shape=input_shape,\n",
    "                        dropout=dropout,\n",
    "                        batch_size=batch_size, epochs=epochs,\n",
    "                        verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, error_score=0) #fit_params={'callbacks': callbacks})\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print('Best score:', grid_result.best_score_, 'using: ', grid_result.best_params_)\n",
    "cv = pd.DataFrame(grid_result.cv_results_)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "cv[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.cv_results_\n",
    "cv = pd.DataFrame(grid_result.cv_results_)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
