{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.tz import gettz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(757566)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'GunPoint' # private_dog0_correct_plus\n",
    "log_to_file = True\n",
    "\n",
    "tensorboard_dir = '../logs/tensorboard'\n",
    "logs_dir = '../logs'\n",
    "timestamp = '{:%Y-%m-%dT%H:%M}'.format(datetime.now(gettz(\"Europe/London\")))\n",
    "logs_dir = logs_dir +'/' + timestamp\n",
    "tensorboard_dir = tensorboard_dir +'/' + timestamp\n",
    "if 'private' in fname:\n",
    "    fdir = '../data/private_data/private_events_dev2' \n",
    "else:\n",
    "    fdir = '../data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    ''' Load a dataset from a file in UCR format\n",
    "    space delimited, class labels in the first column.\n",
    "    Returns\n",
    "    X : DNN input data\n",
    "    Y : class labels\n",
    "    '''\n",
    "    data = np.loadtxt(Path(filename))\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid search adapted from Machine Learning Mastery\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])   \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_functional_model():\n",
    "    # create model\n",
    "    drop = 0.2\n",
    "    num = 64\n",
    "    l2 = 0.1\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(X_SHAPE))\n",
    "    y = Dropout(drop,name='Drop010')(x)\n",
    "    y = Dense(num, kernel_regularizer=regularizers.l2(l2), activation='relu', name='Dense010')(y)\n",
    "    y = Dropout(drop,name='Drop081')(y)\n",
    "    out = Dense(nb_classes-1, activation='sigmoid', name='Dense080')(y)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_fcn(input_shape=(150,1), num_features=100, filter_size=10, pooling_size=3, dropout=0.5):\n",
    "    ''' Create FCN model '''\n",
    "    num_features0 = num_features\n",
    "    num_features1 = math.floor(1.5 * num_features)\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(x)\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.MaxPooling1D(pooling_size)(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    full = keras.layers.GlobalAveragePooling1D()(conv_x)\n",
    "    y = Dropout(dropout,name='Dropout')(full)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(full)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_fcn_simple():\n",
    "    ''' Create FCN model '''\n",
    "    input_shape=(150,1)\n",
    "    num_features=100\n",
    "    filter_size=10\n",
    "    pooling_size=3\n",
    "    dropout=0.5\n",
    "    num_features0 = num_features\n",
    "    num_features1 = math.floor(1.5 * num_features)\n",
    "    nb_classes = 2\n",
    "    x = Input(shape=(input_shape))\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(x)\n",
    "    conv_x = keras.layers.Conv1D(num_features0, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.MaxPooling1D(pooling_size)(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    conv_x = keras.layers.Conv1D(num_features1, filter_size, activation='relu')(conv_x)\n",
    "    full = keras.layers.GlobalAveragePooling1D()(conv_x)\n",
    "    y = Dropout(dropout,name='Dropout')(full)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(full)\n",
    "    model = Model(x, out)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(y):\n",
    "    nb_classes = 2\n",
    "    y = (y - y.min())/(y.max()-y.min())*(nb_classes-1)\n",
    "    Y = utils.to_categorical(y, nb_classes)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1)\n",
      "133/133 [==============================] - 2s 14ms/sample - loss: 0.6940 - acc: 0.5075\n",
      "67/67 [==============================] - 2s 27ms/sample - loss: 0.6942 - acc: 0.4776\n",
      "133/133 [==============================] - 0s 267us/sample - loss: 0.6916 - acc: 0.5113\n",
      "133/133 [==============================] - 2s 16ms/sample - loss: 0.6933 - acc: 0.5038\n",
      "67/67 [==============================] - 2s 27ms/sample - loss: 0.6934 - acc: 0.4627\n",
      "133/133 [==============================] - 0s 189us/sample - loss: 0.6915 - acc: 0.5263\n",
      "134/134 [==============================] - 2s 15ms/sample - loss: 0.6937 - acc: 0.4813\n",
      "66/66 [==============================] - 2s 28ms/sample - loss: 0.6921 - acc: 0.6136\n",
      "134/134 [==============================] - 0s 218us/sample - loss: 0.6924 - acc: 0.5933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 2s 11ms/sample - loss: 0.6968 - acc: 0.4700\n",
      "Best: 0.517500 using {'pooling_size': 4, 'num_features': 32, 'filter_size': 4}\n",
      "0.517500 (0.067745) with: {'pooling_size': 4, 'num_features': 32, 'filter_size': 4}\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "x_train, y_train = readucr(fdir+'/'+fname+'/'+fname+'_TRAIN.txt')\n",
    "x_test, y_test = readucr(fdir+'/'+fname+'/'+fname+'_TEST.txt')\n",
    "X = np.concatenate((x_train, x_test), axis=0)\n",
    "Y = np.concatenate((y_train, y_test), axis=0)\n",
    "X = X.reshape(X.shape + (1,))\n",
    "input_shape = X.shape[1:]\n",
    "print(input_shape)\n",
    "Y = prepare_data(Y)\n",
    "\n",
    "# Add callbacks\n",
    "callbacks = []\n",
    "tb_dir = tensorboard_dir+'/'+fname\n",
    "Path(tb_dir).mkdir(parents=True, exist_ok=True) \n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir=tb_dir, histogram_freq=0))\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "num_features = [32] # [32, 64]\n",
    "filter_size = [4] # [4, 16]\n",
    "pooling_size = [4] # [4, 8]\n",
    "dropout = 0.5\n",
    "param_grid = dict(num_features=num_features, filter_size=filter_size, pooling_size=pooling_size)\n",
    "\n",
    "# Create model and run the grid search\n",
    "model = KerasClassifier(build_fn=create_fcn, \n",
    "                        input_shape=input_shape,\n",
    "                        dropout=dropout,\n",
    "                        batch_size=batch_size, epochs=epochs,\n",
    "                        verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, error_score=0) #fit_params={'callbacks': callbacks})\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print('Best score:', grid_result.best_score_, 'using: ', grid_result.best_params_)\n",
    "cv = pd.DataFrame(grid_result.cv_results_)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "cv[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_pooling_size</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.068176</td>\n",
       "      <td>8.068489</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.513766</td>\n",
       "      <td>4</td>\n",
       "      <td>{'pooling_size': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.545113</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.501082</td>\n",
       "      <td>0.15228</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>0.023449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      28.068176         8.068489              0.5          0.513766   \n",
       "\n",
       "  param_pooling_size               params  rank_test_score  split0_test_score  \\\n",
       "0                  4  {'pooling_size': 4}                1           0.522388   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.488722           0.492537            0.545113   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.484848            0.507463      0.501082         0.15228   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.016196         0.023449  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_\n",
    "cv = pd.DataFrame(grid_result.cv_results_)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
